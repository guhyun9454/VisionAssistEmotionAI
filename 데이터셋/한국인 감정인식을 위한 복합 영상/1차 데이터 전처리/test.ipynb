{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 918/112019 [00:09<18:24, 100.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\인공지능기말프로젝트\\VisionAssistEmotionAI\\데이터셋\\한국인 감정인식을 위한 복합 영상\\데이터 전처리\\test.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%A0%84%EC%B2%98%EB%A6%AC/test.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith((\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.jpeg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%A0%84%EC%B2%98%EB%A6%AC/test.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(source_folder, filename)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%A0%84%EC%B2%98%EB%A6%AC/test.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     img_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfromfile(file_path, np\u001b[39m.\u001b[39;49muint8)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%A0%84%EC%B2%98%EB%A6%AC/test.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimdecode(img_array, cv2\u001b[39m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%A0%84%EC%B2%98%EB%A6%AC/test.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mif\u001b[39;00m img \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "source_folder = 'Cropped_Images' \n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "sum = 0\n",
    "for filename in tqdm(os.listdir(source_folder)):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        file_path = os.path.join(source_folder, filename)\n",
    "\n",
    "        img_array = np.fromfile(file_path, np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        if img is not None:  \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            sum += len(faces)\n",
    "            # print(f\"{filename}: {len(faces)} faces detected\")\n",
    "        # else:\n",
    "        #     print(f\"Failed to load image: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
