{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize_and_save_face(json_path, file_dir_path, save_dir, label, cropped_shape = (256,256)):\n",
    "    #target데이터\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    data_dict = {item[\"filename\"]: item for item in data}\n",
    "\n",
    "    #저장 될 폴더가 존재하지 않으면 생성\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    for filename in tqdm(os.listdir(file_dir_path),desc=f\"processing label {label}\"):\n",
    "        file_path = os.path.join(file_dir_path, filename)\n",
    "\n",
    "        if filename in data_dict:\n",
    "            item = data_dict[filename]\n",
    "\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    face_coords = item[\"annot_A\"][\"boxes\"]\n",
    "                    left = face_coords[\"minX\"]\n",
    "                    right = face_coords[\"maxX\"]\n",
    "                    top = face_coords[\"minY\"]\n",
    "                    bottom = face_coords[\"maxY\"]\n",
    "                    #유효성 검사\n",
    "                    if left >= 0 and top >= 0 and right <= img.width and bottom <= img.height and right > left and bottom > top:\n",
    "                        cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "                        if cropped_img.size != (0, 0):\n",
    "                            resized_img = cropped_img.resize(cropped_shape)\n",
    "                            temp_filename = f\"{label}_{filename}\"\n",
    "                            resized_img.save(os.path.join(save_dir,temp_filename))\n",
    "                            processed_count += 1\n",
    "                            # print(f\"{processed_count} - Successfully cropped and saved {temp_filename}\")\n",
    "                        else:\n",
    "                            # print(f\"Empty cropped image for {filename}\")\n",
    "                            error_count += 1\n",
    "                    else:\n",
    "                        # print(f\"Invalid crop coordinates for {filename}\")\n",
    "                        error_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                error_count += 1\n",
    "    \n",
    "    return processed_count , error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 0: 100%|██████████| 16234/16234 [12:16<00:00, 22.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16117 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 1: 100%|██████████| 15874/15874 [12:10<00:00, 21.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15787 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 2: 100%|██████████| 16133/16133 [12:17<00:00, 21.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16046 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 3: 100%|██████████| 16023/16023 [12:15<00:00, 21.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15930 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 4:  23%|██▎       | 3712/16170 [02:57<09:03, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 4: 100%|██████████| 16170/16170 [12:18<00:00, 21.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16081 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 5: 100%|██████████| 16072/16072 [12:19<00:00, 21.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15984 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 6:  54%|█████▎    | 8668/16197 [06:35<04:18, 29.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 6:  57%|█████▋    | 9182/16197 [06:56<06:07, 19.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: broken data stream when reading image file\n",
      "Error: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing label 6: 100%|██████████| 16197/16197 [12:05<00:00, 22.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16074 123\n",
      "걸린 시간: 5151.46s\n",
      "분노 total_count = 16117, error_count = 117\n",
      "슬픔 total_count = 15787, error_count = 87\n",
      "불안 total_count = 16046, error_count = 87\n",
      "상처 total_count = 15930, error_count = 93\n",
      "당황 total_count = 16081, error_count = 89\n",
      "기쁨 total_count = 15984, error_count = 88\n",
      "중립 total_count = 16074, error_count = 123\n"
     ]
    }
   ],
   "source": [
    "classes = [\"분노\",\"슬픔\",\"불안\",\"상처\",\"당황\",\"기쁨\",\"중립\"]\n",
    "processed_list = []\n",
    "error_list = []\n",
    "start = time.time()\n",
    "for class_index,class_ in enumerate(classes):\n",
    "    json_path = f\"Training\\[라벨]EMOIMG_{class_}_TRAIN\\img_emotion_training_data({class_}).json\"\n",
    "    file_dir_path = f\"Training\\[원천]EMOIMG_{class_}_TRAIN_01\"\n",
    "    save_dir = \"Training/Cropped_Images\"\n",
    "    (processed_count, error_count) = crop_and_resize_and_save_face(json_path, file_dir_path, save_dir,label = class_index,cropped_shape=(256,256))\n",
    "    print(processed_count, error_count)\n",
    "    processed_list.append(processed_count)\n",
    "    error_list.append(error_count)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"걸린 시간: {round(end-start,2)}s\")\n",
    "for class_,processed_count,error_count in zip(classes,processed_list,error_list):\n",
    "    print(class_,f\"total_count = {processed_count}, error_count = {error_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': 'fea9f022fd842f975b69cb66061cd196c2801f54055e68bbed2e3de9868b1c79_남_20_상처_숙박 및 거주공간_20210122135731-010-036.jpeg', 'gender': '남', 'age': 20, 'isProf': '일반인', 'faceExp_uploader': '상처', 'bg_uploader': '숙박 및 거주공간', 'annot_A': {'boxes': {'maxX': 2474.23, 'maxY': 1744.4131951307343, 'minX': 1772.8025999999995, 'minY': 873.0751803107773}, 'faceExp': '중립', 'bg': '숙박 및 거주공간'}, 'annot_B': {'boxes': {'maxX': 2474.2299999999996, 'maxY': 1667.922966471545, 'minX': 1772.8025999999995, 'minY': 842.0446397361302}, 'faceExp': '당황', 'bg': '숙박 및 거주공간'}, 'annot_C': {'boxes': {'maxX': 2474.230000000002, 'maxY': 1766.9074109310811, 'minX': 1772.8026000000011, 'minY': 842.5360180162875}, 'faceExp': '당황', 'bg': '숙박 및 거주공간'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_path = \"데이터 전처리\\원천 데이터\\[라벨]EMOIMG_상처_TRAIN\\img_emotion_training_data(상처).json\"\n",
    "with open(json_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '3df5a5a4ca0b4dd57db2d3ac1284c74c5a7b66e0d47ebc5522d5361de8940ada_여_30_기쁨_상업시설&점포&시장_20210122161328-003-022.jpg', 'gender': '여', 'age': 30, 'isProf': '일반인', 'faceExp_uploader': '기쁨', 'bg_uploader': '상업시설/점포/시장', 'annot_A': {'boxes': {'maxX': 2074.0167999999994, 'maxY': 2018.5946, 'minX': 1275.454, 'minY': 918.8821}, 'faceExp': '기쁨', 'bg': '상업시설/점포/시장'}, 'annot_B': {'boxes': {'maxX': 2074.0168000000003, 'maxY': 2018.5946, 'minX': 1275.4540000000002, 'minY': 918.8821}, 'faceExp': '기쁨', 'bg': '상업시설/점포/시장'}, 'annot_C': {'boxes': {'maxX': 2074.3103785516796, 'maxY': 2018.5589175816149, 'minX': 1312.9604214483209, 'minY': 912.617782418385}, 'faceExp': '기쁨', 'bg': '상업시설/점포/시장'}}\n"
     ]
    }
   ],
   "source": [
    "print(data[40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def crop_and_resize_and_save_face_2(json_path, file_dir_path, save_dir, cropped_shape=(256, 256)):\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    data_dict = {item[\"filename\"]: item for item in data}\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    for filename in tqdm(os.listdir(file_dir_path), desc=\"Processing\"):\n",
    "        file_path = os.path.join(file_dir_path, filename)\n",
    "\n",
    "        if filename in data_dict:\n",
    "            item = data_dict[filename]\n",
    "\n",
    "            # 업로더와 검수자 간의 일치 여부 확인\n",
    "            uploader_emotion = item[\"faceExp_uploader\"]\n",
    "            annotations = [item.get(\"annot_A\", {}).get(\"faceExp\", \"\"),\n",
    "                           item.get(\"annot_B\", {}).get(\"faceExp\", \"\"),\n",
    "                           item.get(\"annot_C\", {}).get(\"faceExp\", \"\")]\n",
    "            \n",
    "            # 일치하는 감정의 수 확인\n",
    "            matching_emotions = sum(emotion == uploader_emotion for emotion in annotations)\n",
    "\n",
    "            if matching_emotions >= 2: #2명 이상의 검수자가 업로더의 표정과 동의하는 경우만 사용\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        face_coords = item[\"annot_A\"][\"boxes\"]\n",
    "                        left = face_coords[\"minX\"]\n",
    "                        right = face_coords[\"maxX\"]\n",
    "                        top = face_coords[\"minY\"]\n",
    "                        bottom = face_coords[\"maxY\"]\n",
    "\n",
    "                        # 유효성 검사\n",
    "                        if 0 <= left < right <= img.width and 0 <= top < bottom <= img.height:\n",
    "                            cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "                            if cropped_img.size != (0, 0):\n",
    "                                resized_img = cropped_img.resize(cropped_shape)\n",
    "                                temp_filename = f\"{filename[:-5]}_cropped.jpg\"\n",
    "                                resized_img.save(os.path.join(save_dir, temp_filename))\n",
    "                                processed_count += 1\n",
    "                            else:\n",
    "                                error_count += 1\n",
    "                        else:\n",
    "                            error_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    error_count += 1\n",
    "    \n",
    "    return processed_count, error_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "cropped_1 = \"데이터 전처리/2차 검수/2차_검수_종합\"\n",
    "classes = [\"분노\",\"슬픔\",\"불안\",\"상처\",\"당황\",\"기쁨\",\"중립\"]\n",
    "classes_dict = []\n",
    "\n",
    "for class_ in classes:\n",
    "    json_path =f\"데이터 전처리\\원천 데이터\\[라벨]EMOIMG_{class_}_TRAIN\\img_emotion_training_data({class_}).json\"\n",
    "\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    classes_dict.append({item[\"filename\"].split(\".\")[0]: item for item in data})\n",
    "    \n",
    "# for img in os.listdir(cropped_1):\n",
    "#     print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def find_majority_agreement(annotations):\n",
    "    \"\"\"\n",
    "    검수자들의 감정 중 최소 두 명 이상이 동의하는 감정을 찾는 함수.\n",
    "    \"\"\"\n",
    "    emotion_counts = Counter(annotations)\n",
    "    for emotion, count in emotion_counts.items():\n",
    "        if count >= 2:\n",
    "            return emotion\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73326/73326 [00:00<00:00, 102398.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7439, 6782, 4124, 2103, 8243, 10326, 10387]\n",
      "[8834, 9675, 6084, 3544, 10628, 10872, 13420]\n",
      "[4995, 4246, 1447, 571, 5372, 9699, 7910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "two_or_more_agree_with_uploader = [0 for _ in range(7)]\n",
    "two_or_more = [0 for _ in range(7)]\n",
    "all_agree = [0 for _ in range(7)]\n",
    "\n",
    "classes = [\"분노\",\"슬픔\",\"불안\",\"상처\",\"당황\",\"기쁨\",\"중립\"]\n",
    "\n",
    "for img in tqdm(os.listdir(cropped_1)):\n",
    "    temp = (img.split(\".\")[0]).split(\"_\")\n",
    "    filename = \"_\".join(temp[1:])\n",
    "    label = int(temp[0])\n",
    "    item = classes_dict[label][filename]\n",
    "\n",
    "    # 업로더의 감정을 검수자 두명 이상이서 동의\n",
    "    uploader_emotion = item[\"faceExp_uploader\"]\n",
    "    annotations = [item.get(\"annot_A\", {}).get(\"faceExp\", \"\"),\n",
    "                    item.get(\"annot_B\", {}).get(\"faceExp\", \"\"),\n",
    "                    item.get(\"annot_C\", {}).get(\"faceExp\", \"\")]\n",
    "    majority = find_majority_agreement(annotations)\n",
    "    if majority and majority != \"알수없음\":\n",
    "        if uploader_emotion == majority:\n",
    "            if annotations.count(majority) ==  3:\n",
    "                all_agree[label] += 1\n",
    "            two_or_more_agree_with_uploader[label] += 1\n",
    "        two_or_more[classes.index(majority)] += 1\n",
    "\n",
    "\n",
    "print(two_or_more_agree_with_uploader)\n",
    "print(two_or_more)\n",
    "print(all_agree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차 데이터 전처리\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\인공지능기말프로젝트\\VisionAssistEmotionAI\\데이터셋\\한국인 감정인식을 위한 복합 영상\\data_pre_processing.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/data_pre_processing.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m processed_list \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/data_pre_processing.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m error_list \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/data_pre_processing.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/data_pre_processing.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m class_index,class_ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B8%B0%EB%A7%90%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/VisionAssistEmotionAI/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B/%ED%95%9C%EA%B5%AD%EC%9D%B8%20%EA%B0%90%EC%A0%95%EC%9D%B8%EC%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B3%B5%ED%95%A9%20%EC%98%81%EC%83%81/data_pre_processing.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     json_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m데이터 전처리\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m원천 데이터\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[라벨]EMOIMG_\u001b[39m\u001b[39m{\u001b[39;00mclass_\u001b[39m}\u001b[39;00m\u001b[39m_TRAIN\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mimg_emotion_training_data(\u001b[39m\u001b[39m{\u001b[39;00mclass_\u001b[39m}\u001b[39;00m\u001b[39m).json\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "classes = [\"분노\",\"슬픔\",\"불안\",\"상처\",\"당황\",\"기쁨\",\"중립\"]\n",
    "processed_list = []\n",
    "error_list = []\n",
    "start = time.time()\n",
    "for class_index,class_ in enumerate(classes):\n",
    "    json_path = f\"데이터 전처리\\원천 데이터\\[라벨]EMOIMG_{class_}_TRAIN\\img_emotion_training_data({class_}).json\"\n",
    "    file_dir_path = f\"데이터 전처리\\원천 데이터\\[원천]EMOIMG_{class_}_TRAIN_04\"\n",
    "    save_dir = \"Training/Cropped_Images2\"\n",
    "    (processed_count, error_count) = crop_and_resize_and_save_face(json_path, file_dir_path, save_dir,label = class_index,cropped_shape=(256,256))\n",
    "    print(processed_count, error_count)\n",
    "    processed_list.append(processed_count)\n",
    "    error_list.append(error_count)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"걸린 시간: {round(end-start,2)}s\")\n",
    "for class_,processed_count,error_count in zip(classes,processed_list,error_list):\n",
    "    print(class_,f\"total_count = {processed_count}, error_count = {error_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
