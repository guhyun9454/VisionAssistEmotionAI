{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import models, regularizers, optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51328 images belonging to 7 classes.\n",
      "Found 10999 images belonging to 7 classes.\n",
      "Found 10999 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dir = \"../데이터셋/한국인 감정인식을 위한 복합 영상/최종데이터셋/train\"\n",
    "val_dir = \"../데이터셋/한국인 감정인식을 위한 복합 영상/최종데이터셋/val\"\n",
    "test_dir = \"../데이터셋/한국인 감정인식을 위한 복합 영상/최종데이터셋/test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,481,031\n",
      "Trainable params: 122,481,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential(name=\"vgg11\")\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01), input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(2048, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "checkpoint_path = \"saved_models/vgg11_best_model.hdf5\"\n",
    "checkpoint_cb = ModelCheckpoint(checkpoint_path, verbose=1, save_best_only=True,monitor='val_loss')\n",
    "early_stop_cb = EarlyStopping(patience=15,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 10.8358 - accuracy: 0.1436\n",
      "Epoch 1: val_loss improved from inf to 2.03031, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 350s 205ms/step - loss: 10.8358 - accuracy: 0.1436 - val_loss: 2.0303 - val_accuracy: 0.1491 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9593 - accuracy: 0.1458\n",
      "Epoch 2: val_loss improved from 2.03031 to 1.94622, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 329s 205ms/step - loss: 1.9593 - accuracy: 0.1458 - val_loss: 1.9462 - val_accuracy: 0.1409 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9463 - accuracy: 0.1458\n",
      "Epoch 3: val_loss improved from 1.94622 to 1.94590, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 326s 203ms/step - loss: 1.9463 - accuracy: 0.1458 - val_loss: 1.9459 - val_accuracy: 0.1452 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9464 - accuracy: 0.1452\n",
      "Epoch 4: val_loss did not improve from 1.94590\n",
      "1604/1604 [==============================] - 318s 198ms/step - loss: 1.9464 - accuracy: 0.1452 - val_loss: 1.9460 - val_accuracy: 0.1491 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9464 - accuracy: 0.1469\n",
      "Epoch 5: val_loss did not improve from 1.94590\n",
      "1604/1604 [==============================] - 319s 199ms/step - loss: 1.9464 - accuracy: 0.1469 - val_loss: 1.9459 - val_accuracy: 0.1415 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9465 - accuracy: 0.1441\n",
      "Epoch 6: val_loss did not improve from 1.94590\n",
      "1604/1604 [==============================] - 316s 197ms/step - loss: 1.9465 - accuracy: 0.1441 - val_loss: 1.9459 - val_accuracy: 0.1493 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9464 - accuracy: 0.1462\n",
      "Epoch 7: val_loss improved from 1.94590 to 1.94583, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 314s 195ms/step - loss: 1.9464 - accuracy: 0.1462 - val_loss: 1.9458 - val_accuracy: 0.1489 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9463 - accuracy: 0.1471\n",
      "Epoch 8: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 312s 195ms/step - loss: 1.9463 - accuracy: 0.1471 - val_loss: 1.9459 - val_accuracy: 0.1450 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9463 - accuracy: 0.1457\n",
      "Epoch 9: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 323s 201ms/step - loss: 1.9463 - accuracy: 0.1457 - val_loss: 1.9460 - val_accuracy: 0.1451 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9465 - accuracy: 0.1426\n",
      "Epoch 10: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 321s 200ms/step - loss: 1.9465 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1492 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9464 - accuracy: 0.1462\n",
      "Epoch 11: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 316s 197ms/step - loss: 1.9464 - accuracy: 0.1462 - val_loss: 1.9463 - val_accuracy: 0.1450 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9464 - accuracy: 0.1449\n",
      "Epoch 12: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 307s 191ms/step - loss: 1.9464 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1491 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9462 - accuracy: 0.1472\n",
      "Epoch 13: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 298s 186ms/step - loss: 1.9462 - accuracy: 0.1472 - val_loss: 1.9466 - val_accuracy: 0.1378 - lr: 0.0100\n",
      "Epoch 14/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9463 - accuracy: 0.1419\n",
      "Epoch 14: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9463 - accuracy: 0.1419 - val_loss: 1.9461 - val_accuracy: 0.1489 - lr: 0.0100\n",
      "Epoch 15/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9463 - accuracy: 0.1452\n",
      "Epoch 15: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9463 - accuracy: 0.1452 - val_loss: 1.9463 - val_accuracy: 0.1413 - lr: 0.0100\n",
      "Epoch 16/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9464 - accuracy: 0.1441\n",
      "Epoch 16: val_loss did not improve from 1.94583\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9464 - accuracy: 0.1441 - val_loss: 1.9467 - val_accuracy: 0.1447 - lr: 0.0100\n",
      "Epoch 17/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
      "Epoch 17: val_loss improved from 1.94583 to 1.94566, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 297s 185ms/step - loss: 1.9460 - accuracy: 0.1457 - val_loss: 1.9457 - val_accuracy: 0.1490 - lr: 1.0000e-03\n",
      "Epoch 18/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1486\n",
      "Epoch 18: val_loss improved from 1.94566 to 1.94565, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 297s 185ms/step - loss: 1.9457 - accuracy: 0.1486 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-03\n",
      "Epoch 19/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9458 - accuracy: 0.1490\n",
      "Epoch 19: val_loss improved from 1.94565 to 1.94563, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 297s 185ms/step - loss: 1.9458 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-03\n",
      "Epoch 20/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1480\n",
      "Epoch 20: val_loss improved from 1.94563 to 1.94562, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 297s 185ms/step - loss: 1.9457 - accuracy: 0.1480 - val_loss: 1.9456 - val_accuracy: 0.1492 - lr: 1.0000e-03\n",
      "Epoch 21/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1490\n",
      "Epoch 21: val_loss did not improve from 1.94562\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9457 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-03\n",
      "Epoch 22/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1479\n",
      "Epoch 22: val_loss did not improve from 1.94562\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9457 - accuracy: 0.1479 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-03\n",
      "Epoch 23/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1490\n",
      "Epoch 23: val_loss did not improve from 1.94562\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9457 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1489 - lr: 1.0000e-03\n",
      "Epoch 24/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1490\n",
      "Epoch 24: val_loss did not improve from 1.94562\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9457 - accuracy: 0.1490 - val_loss: 1.9457 - val_accuracy: 0.1489 - lr: 1.0000e-03\n",
      "Epoch 25/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1490\n",
      "Epoch 25: val_loss did not improve from 1.94562\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9457 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-03\n",
      "Epoch 26/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1490\n",
      "Epoch 26: val_loss did not improve from 1.94562\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9457 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1492 - lr: 1.0000e-03\n",
      "Epoch 27/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1490\n",
      "Epoch 27: val_loss did not improve from 1.94562\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9457 - accuracy: 0.1490 - val_loss: 1.9457 - val_accuracy: 0.1489 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9457 - accuracy: 0.1490\n",
      "Epoch 28: val_loss did not improve from 1.94562\n",
      "1604/1604 [==============================] - 318s 198ms/step - loss: 1.9457 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1493 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 29: val_loss improved from 1.94562 to 1.94561, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 316s 197ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1492 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 30: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 313s 195ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 31: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 298s 185ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 32: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 294s 183ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 33: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1489 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 34: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 183ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 35: val_loss improved from 1.94561 to 1.94561, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 296s 185ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 36: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 37: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 294s 183ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 38: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1489 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 39: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 40: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1489 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 41: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 42: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 43: val_loss improved from 1.94561 to 1.94561, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 297s 185ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1492 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 44: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1488 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 45: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 387s 241ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 46: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 402s 251ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 47: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 401s 250ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1493 - lr: 1.0000e-06\n",
      "Epoch 48/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 48: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 400s 249ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-06\n",
      "Epoch 49/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 49: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 401s 250ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1494 - lr: 1.0000e-06\n",
      "Epoch 50/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 50: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 400s 249ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1489 - lr: 1.0000e-06\n",
      "Epoch 51/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 51: val_loss improved from 1.94561 to 1.94561, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 401s 250ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-06\n",
      "Epoch 52/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 52: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 401s 250ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-06\n",
      "Epoch 53/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 53: val_loss did not improve from 1.94561\n",
      "1604/1604 [==============================] - 318s 198ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-06\n",
      "Epoch 54/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 54: val_loss improved from 1.94561 to 1.94560, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 316s 197ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-06\n",
      "Epoch 55/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 55: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 296s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-06\n",
      "Epoch 56/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 56: val_loss improved from 1.94560 to 1.94560, saving model to saved_models\\vgg11_best_model.hdf5\n",
      "1604/1604 [==============================] - 299s 186ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-06\n",
      "Epoch 57/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 57: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-07\n",
      "Epoch 58/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 58: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-07\n",
      "Epoch 59/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 59: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1494 - lr: 1.0000e-07\n",
      "Epoch 60/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 60: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-07\n",
      "Epoch 61/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 61: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1493 - lr: 1.0000e-07\n",
      "Epoch 62/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 62: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1492 - lr: 1.0000e-07\n",
      "Epoch 63/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 63: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1488 - lr: 1.0000e-07\n",
      "Epoch 64/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 64: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-07\n",
      "Epoch 65/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 65: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-07\n",
      "Epoch 66/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 66: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1489 - lr: 1.0000e-07\n",
      "Epoch 67/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 67: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-08\n",
      "Epoch 68/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 68: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-08\n",
      "Epoch 69/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 69: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1490 - lr: 1.0000e-08\n",
      "Epoch 70/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 70: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1492 - lr: 1.0000e-08\n",
      "Epoch 71/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.9456 - accuracy: 0.1490\n",
      "Epoch 71: val_loss did not improve from 1.94560\n",
      "1604/1604 [==============================] - 295s 184ms/step - loss: 1.9456 - accuracy: 0.1490 - val_loss: 1.9456 - val_accuracy: 0.1491 - lr: 1.0000e-08\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=300,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[checkpoint_cb,early_stop_cb,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 44s 128ms/step - loss: 1.9456 - accuracy: 0.1490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9456193447113037, 0.14901354908943176]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn3ElEQVR4nO3dfXCU1d3/8c8mu9kECKFAA0TCg0BFVPABayGM4oi0Cj5Mf60P1RHLWLWioFif8An0lqC3pZRicbQO4lilnVIpLbUCFYLcQFEe2oj8CAjFjJZfvBUTEA2YnN8fcF2bAEHYPTlnN3m/ZnZMrt3Nnusiwme+55zrGzHGGAEAAGSoLN8DAAAASAVhBgAAZDTCDAAAyGiEGQAAkNEIMwAAIKMRZgAAQEYjzAAAgIwW9T2A5lZfX6+PPvpI+fn5ikQivocDAACOgzFGe/bsUVFRkbKyjl17afFh5qOPPlJxcbHvYQAAgCRUVlaqe/fux3xNiw8z+fn5kg5ejPbt23seDQAAOB41NTUqLi4O/x0/lhYfZoKppfbt2xNmAADIMMezRIQFwAAAIKMRZgAAQEYjzAAAgIxGmAEAABmNMAMAADIaYQYAAGQ0wgwAAMhohBkAAJDRCDMAACCjEWYAAEBGI8wAAICMRpgBAAAZrcU3mmwue2u/0mf79isvlq1O7eK+hwMAQKtFZSZJL/7PDg17cpn++40tvocCAECrRphJUjT74KU7UGc8jwQAgNaNMJOkaFZEkvRVfb3nkQAA0LoRZpIUO1SZ+YrKDAAAXhFmkhTNPliZOVBHZQYAAJ8IM0mKZR2qzNRTmQEAwCfCTJKys6jMAACQDggzSQqmmVgzAwCAX4SZJAULgOuYZgIAwCvCTJKCrdkH2JoNAIBXhJkksTUbAID0QJhJEluzAQBID4SZJEXZmg0AQFogzCQpFu5mojIDAIBPhJkk0WgSAID0QJhJEo0mAQBID4SZJLGbCQCA9ECYSRK7mQAASA+EmSQlppmozAAA4BNhJklRppkAAEgLhJkkxVgADABAWiDMJCmozNQbqZ6pJgAAvCHMJClYACzRbBIAAJ8IM0mKZSUuHetmAADwhzCTpIaVGcIMAAD+EGaSFGzNlphmAgDAJ8JMkiKRSOJeM1RmAADwhjCTAu4CDACAf4SZFASLgLkLMAAA/ngNMytWrNBll12moqIiRSIRLViwoNHzxhhNnjxZRUVFysvL0/Dhw7Vp0yY/gz2KoDLzFZUZAAC88RpmPv/8cw0aNEizZs066vNPPfWUpk+frlmzZuntt99W165ddfHFF2vPnj2OR3p02YcqMwdYMwMAgDdRnx9+ySWX6JJLLjnqc8YYzZgxQw8++KC+//3vS5Lmzp2rLl266JVXXtEtt9zicqhHFcumpQEAAL6l7ZqZHTt2aNeuXRo5cmR4LB6P64ILLtCqVauafF9tba1qamoaPZpLOM3EmhkAALxJ2zCza9cuSVKXLl0aHe/SpUv43NGUlpaqoKAgfBQXFzfbGMMFwEwzAQDgTdqGmUAkEmn0vTHmiGMNPfDAA6qurg4flZWVzTY2FgADAOCf1zUzx9K1a1dJBys03bp1C49XVVUdUa1pKB6PKx6PN/v4JCkaLABmmgkAAG/StjLTu3dvde3aVUuWLAmP7d+/X2VlZRo6dKjHkSXEqMwAAOCd18rM3r17tW3btvD7HTt2aOPGjerYsaN69OihO++8U1OnTlW/fv3Ur18/TZ06VW3atNGPfvQjj6NOiGazNRsAAN+8hpl33nlHF154Yfj9xIkTJUljxozRiy++qHvvvVdffPGFbrvtNu3evVvnnXeeFi9erPz8fF9DbiTszcTWbAAAvPEaZoYPHy5jmq5qRCIRTZ48WZMnT3Y3qBMQy2Y3EwAAvqXtmplMQKNJAAD8I8ykIDHNRGUGAABfCDMpiIY3zaMyAwCAL4SZFCSmmajMAADgC2EmBcEC4DqmmQAA8IYwk4JgzcwBtmYDAOANYSYFUbZmAwDgHWEmBbQzAADAP8JMCmg0CQCAf4SZFFCZAQDAP8JMCtiaDQCAf4SZFIQ3zWM3EwAA3hBmUpCYZqIyAwCAL4SZFGQHC4AJMwAAeEOYSUFYmWGaCQAAbwgzKQi7ZlOZAQDAG8JMCsI7AFOZAQDAG8JMClgADACAf4SZFHAHYAAA/CPMpCDKHYABAPCOMJOCGF2zAQDwjjCTgmA30wEWAAMA4A1hJgVUZgAA8I8wk4JEo0kqMwAA+EKYSUGi0SSVGQAAfCHMpIDdTAAA+EeYSUG4AJg1MwAAeEOYSUGMdgYAAHhHmElBMM1Ux5oZAAC8IcykIGxnwDQTAADeEGZSEGMBMAAA3hFmUhDNptEkAAC+EWZSEMuiMgMAgG+EmRQElZl6I9VTnQEAwAvCTAqC3UwSzSYBAPCFMJOCWFbi8tFsEgAAPwgzKWhYmSHMAADgB2EmBUE7A4lpJgAAfCHMpCASiSg73NFEZQYAAB8IMylKNJukMgMAgA+EmRQFzSbpzwQAgB+EmRQFi4DpnA0AgB+EmRTRbBIAAL8IMylKNJskzAAA4ANhJkXBNBNbswEA8IMwk6LgLsBUZgAA8IMwk6JwATBbswEA8IIwk6JwATBbswEA8IIwkyIqMwAA+EWYSVHiDsBUZgAA8IEwk6LooTsAc9M8AAD8IMykiPvMAADgF2EmRcEC4K9YAAwAgBeEmRTFWAAMAIBXhJkUsTUbAAC/CDMpYms2AAB+EWZSFMumnQEAAD4RZlIU3meGrdkAAHhBmElRlMoMAABeEWZSxG4mAAD8IsykKDucZqIyAwCAD4SZFCUWAFOZAQDAB8JMimg0CQCAX4SZFNFoEgAAv9I6zHz11Vd66KGH1Lt3b+Xl5enkk0/WY489pvo0Cg6xQ5WZOtbMAADgRdT3AI7lySef1LPPPqu5c+fqtNNO0zvvvKMf//jHKigo0IQJE3wPT1KiMsM0EwAAfqR1mFm9erWuuOIKjRo1SpLUq1cvvfrqq3rnnXc8jyyBrdkAAPiV1tNMw4YN09///ndVVFRIkv75z39q5cqVuvTSS5t8T21trWpqaho9mlOUrdkAAHiV1pWZ++67T9XV1erfv7+ys7NVV1enJ554Qtdee22T7yktLdWUKVOcjTHK1mwAALxK68rM7373O7388st65ZVXtH79es2dO1dPP/205s6d2+R7HnjgAVVXV4ePysrKZh1jYpqJygwAAD6kdWXmnnvu0f33369rrrlGknTGGWdo586dKi0t1ZgxY476nng8rng87myM0axDC4CZZgIAwIu0rszs27dPWVmNh5idnZ1WW7OjLAAGAMCrtK7MXHbZZXriiSfUo0cPnXbaadqwYYOmT5+usWPH+h5aKKjMMM0EAIAfaR1mfvWrX+nhhx/WbbfdpqqqKhUVFemWW27RI4884ntooaAycyCNqkUAALQmaR1m8vPzNWPGDM2YMcP3UJrEAmAAAPxK6zUzmSBcAMyaGQAAvCDMpCiYZqI3EwAAfhBmUhQLu2YTZgAA8IEwk6KwnQHTTAAAeEGYSVFYmWEBMAAAXhBmUhTeNI+t2QAAeEGYSVFiNxOVGQAAfCDMpChGOwMAALwizKQomk2jSQAAfCLMpCjYzURlBgAAPwgzKQrCTL2R6qnOAADgHGEmRcE0k0SzSQAAfCDMpChYACxxrxkAAHwgzKQo2Jot0dIAAAAfCDMpalyZYZoJAADXCDMpikQiyg52NFGZAQDAOcKMBTSbBADAH8KMBTSbBADAH8KMBTSbBADAH8KMBTSbBADAH8KMBYmWBoQZAABcI8xYEEwzcQdgAADcI8xYwAJgAAD8IcxYQOdsAAD8IcxYEDSbPMBN8wAAcI4wY0HQ0qCONTMAADhHmLEgcQdgKjMAALhGmLEgygJgAAC8IcxYEOMOwAAAeEOYsYA7AAMA4A9hxoKwMsPWbAAAnCPMWBBWZtiaDQCAc4QZC7KpzAAA4A1hxoIYjSYBAPCGMGNB4g7AVGYAAHCNMGNBYgEwlRkAAFwjzFgQLABmzQwAAO4RZiyIhjfNozIDAIBrhBkLYkE7A8IMAADOEWYsSDSaZJoJAADXCDMW0GgSAAB/CDMWhPeZYWs2AADOEWYsCO8zQ2UGAADnCDMW0GgSAAB/CDMWZAcLgNnNBACAc0mFmblz52rRokXh9/fee686dOigoUOHaufOndYGlykSC4CpzAAA4FpSYWbq1KnKy8uTJK1evVqzZs3SU089pc6dO+uuu+6yOsBMQKNJAAD8iSbzpsrKSvXt21eStGDBAv3gBz/QzTffrJKSEg0fPtzm+DJCotEkYQYAANeSqsy0a9dOn3zyiSRp8eLFGjFihCQpNzdXX3zxhb3RZQgWAAMA4E9SlZmLL75YN910k8466yxVVFRo1KhRkqRNmzapV69eNseXEcJGk1RmAABwLqnKzDPPPKMhQ4bo448/1vz589WpUydJ0rp163TttddaHWAmiFKZAQDAm6QqMx06dNCsWbOOOD5lypSUB5SJYnTNBgDAm6QqM3/729+0cuXK8PtnnnlGZ555pn70ox9p9+7d1gaXKYJpJu4ADACAe0mFmXvuuUc1NTWSpPLyct1999269NJLtX37dk2cONHqADMB00wAAPiT1DTTjh07NGDAAEnS/PnzNXr0aE2dOlXr16/XpZdeanWAmSCWzQJgAAB8Saoyk5OTo3379kmSli5dqpEjR0qSOnbsGFZsWpNo0M6AygwAAM4lVZkZNmyYJk6cqJKSEq1du1a/+93vJEkVFRXq3r271QFmgnBrNmtmAABwLqnKzKxZsxSNRvWHP/xBs2fP1kknnSRJev311/W9733P6gAzQbhmpp7KDAAAriVVmenRo4f+8pe/HHH8F7/4RcoDykTB1mx2MwEA4F5SYUaS6urqtGDBAm3evFmRSESnnnqqrrjiCmVnZ9scX0ZITDNRmQEAwLWkwsy2bdt06aWX6sMPP9Qpp5wiY4wqKipUXFysRYsWqU+fPrbHmdaCaSYaTQIA4F5Sa2bGjx+vPn36qLKyUuvXr9eGDRv0wQcfqHfv3ho/frztMaa9YGt2HWEGAADnkqrMlJWVac2aNerYsWN4rFOnTpo2bZpKSkqsDS5TBFuz6+qNjDGKRCKeRwQAQOuRVGUmHo9rz549Rxzfu3evcnJyUh5UpolmJy4ji4ABAHArqTAzevRo3XzzzfrHP/4hYw5WI9asWaNbb71Vl19+ue0xpr1gN5PE9mwAAFxLKszMnDlTffr00ZAhQ5Sbm6vc3FwNHTpUffv21YwZM6wO8MMPP9T111+vTp06qU2bNjrzzDO1bt06q5+RqmA3k0RlBgAA15JaM9OhQwf96U9/0rZt27R582YZYzRgwAD17dvX6uB2796tkpISXXjhhXr99ddVWFio999/Xx06dLD6OalqVJlhezYAAE4dd5j5um7Yy5cvD7+ePn160gNq6Mknn1RxcbHmzJkTHuvVq5eVn21TJBJRdlZEdfWGZpMAADh23GFmw4YNx/U6mzt5Fi5cqO9+97v64Q9/qLKyMp100km67bbb9JOf/KTJ99TW1qq2tjb83lXjyyDM0GwSAAC3jjvMLFu2rDnHcVTbt2/X7NmzNXHiRE2aNElr167V+PHjFY/HdcMNNxz1PaWlpZoyZYrjkUqxrIj2i2aTAAC4FjHGpO2/vjk5ORo8eLBWrVoVHhs/frzefvttrV69+qjvOVplpri4WNXV1Wrfvn2zjXXQlMWq/uKAlk48X30L85vtcwAAaA1qampUUFBwXP9+J7WbyZVu3bppwIABjY6deuqp+uCDD5p8TzweV/v27Rs9XKDZJAAAfqR1mCkpKdGWLVsaHauoqFDPnj09jahpiWaThBkAAFxK6zBz1113ac2aNZo6daq2bdumV155Rc8995zGjRvne2hHCJpNctM8AADcSuswc+655+q1117Tq6++qtNPP12PP/64ZsyYoeuuu8730I4QNJtkazYAAG4lddM8l0aPHq3Ro0f7HsbXCppNsjUbAAC30royk0mCZpOsmQEAwC3CjCUx1swAAOAFYcaSxDQTlRkAAFwizFjC1mwAAPwgzFjC1mwAAPwgzFgSLABmmgkAALcIM5bEDq2Z+Yqt2QAAOEWYsSSYZjrATfMAAHCKMGNJ4j4zVGYAAHCJMGNJMM1UR2UGAACnCDOWsAAYAAA/CDOWhHcAZpoJAACnCDOWBDfNYwEwAABuEWYsiVKZAQDAC8KMJbFgNxOVGQAAnCLMWJIdNpqkMgMAgEuEGUsSdwCmMgMAgEuEGUvCm+bRaBIAAKcIM5aE7QyozAAA4BRhxpJYFu0MAADwgTBjCY0mAQDwgzBjSbBmpo5pJgAAnCLMWBLuZmIBMAAAThFmLKHRJAAAfhBmLAkbTVKZAQDAKcKMJWGjSSozAAA4RZixhEaTAAD4QZixJBouAKYyAwCAS4QZS1gADACAH4QZSxKNJplmAgDAJcKMJYlGk1RmAABwiTBjSaLRJJUZAABcIsxYkmg0SWUGAACXCDOWhFuzmWYCAMApwowl3AEYAAA/CDOWRJlmAgDAC8KMJSwABgDAD8KMJTG2ZgMA4AVhxpKgnUFdvZExBBoAAFwhzFgSrJmRaGkAAIBLhBlLgjUzEjuaAABwiTBjScMwQ2UGAAB3CDOWxBpMM9FsEgAAdwgzlmRlRXRoDTA7mgAAcIgwY1HQOZt7zQAA4A5hxqJYg+3ZAADADcKMRYnKDGEGAABXCDMW0WwSAAD3CDMW0WwSAAD3CDMW0WwSAAD3CDMWBf2Z2JoNAIA7hBmL2JoNAIB7hBmLwsoMa2YAAHCGMGNR7FBlht1MAAC4Q5ixKLEAmMoMAACuEGYsirE1GwAA5wgzFkW5aR4AAM4RZiwKdjNRmQEAwB3CjEWxLCozAAC4RpixiAXAAAC4R5ixKDHNRGUGAABXCDMWxWhnAACAc4QZi7KzgnYGhBkAAFwhzFgUC7ZmM80EAIAzhBmLwgXATDMBAOBMRoWZ0tJSRSIR3Xnnnb6HclTRLBYAAwDgWsaEmbffflvPPfecBg4c6HsoTQqnmajMAADgTEaEmb179+q6667T888/r2984xvHfG1tba1qamoaPVwJtmYfoDIDAIAzGRFmxo0bp1GjRmnEiBFf+9rS0lIVFBSEj+LiYgcjPCjcms1uJgAAnEn7MDNv3jytX79epaWlx/X6Bx54QNXV1eGjsrKymUeYEN40j2kmAACcifoewLFUVlZqwoQJWrx4sXJzc4/rPfF4XPF4vJlHdnRRtmYDAOBcWoeZdevWqaqqSuecc054rK6uTitWrNCsWbNUW1ur7OxsjyNsLJZFZQYAANfSOsxcdNFFKi8vb3Tsxz/+sfr376/77rsvrYKM1LDRJJUZAABcSeswk5+fr9NPP73RsbZt26pTp05HHE8HiUaTVGYAAHAl7RcAZ5Jo2GiSygwAAK6kdWXmaJYvX+57CE0KwgyNJgEAcIfKjEWxcGs2lRkAAFwhzFiUWABMZQYAAFcIMxbRaBIAAPcIMxbRaBIAAPcIMxYlGk0SZgAAcIUwY1Gi0STTTAAAuEKYsSiozNQxzQQAgDOEGYvC3UxszQYAwBnCjEVho0nWzAAA4AxhxiLuMwMAgHuEGYvozQQAgHuEGYvomg0AgHuEGYsSjSapzAAA4AphxqJEo0kqMwAAuEKYsShYAFxXb2QMgQYAABcIMxYFW7MldjQBAOAKYcaioDIjsaMJAABXCDMWNQwzVGYAAHCDMGNRw2km+jMBAOAGYcairKyIDu3OpnM2AACOEGYsC26cd4DKDAAAThBmLAtbGlCZAQDACcKMZYm7AFOZAQDABcKMZYm7AFOZAQDABcKMZcH2bJpNAgDgBmHGsuih7dk0mwQAwA3CjGWxoDLDbiYAAJwgzFgWbs2mMgMAgBOEGcsSW7OpzAAA4AJhxjJ2MwEA4BZhxjJ2MwEA4BZhxrKg2SQLgAEAcIMwY1lQmWEBMAAAbhBmLMtmATAAAE4RZixjATAAAG4RZiyj0SQAAG4RZiwLKzOsmQEAwAnCjGVR2hkAAOAUYcayRKNJwgwAAC4QZiwLG00yzQQAgBOEGcvC+8wwzQQAgBOEGcuCaSYqMwAAuEGYsSyYZqqjMgMAgBOEGcui2SwABgDAJcKMZbGgnQF3AAYAwAnCjGXZbM0GAMApwoxlUbZmAwDgFGHGshh3AAYAwCnCjGWJOwBTmQEAwAXCjGWJOwBTmQEAwAXCjGXB1mx2MwEA4AZhxrLooa3Z7GYCAMANwoxlMSozAAA4RZixLGw0SWUGAAAnCDOWBbuZ6M0EAIAbhBnLYtw0DwAApwgzltFoEgAAtwgzlkVpNAkAgFOEGcvCMENlBgAAJwgzloXTTFRmAABwgjBjGe0MAABwizBjWaLRJGEGAAAXCDOWhZUZppkAAHCCMGNZ2GiSygwAAE6kdZgpLS3Vueeeq/z8fBUWFurKK6/Uli1bfA/rmBKNJqnMAADgQlqHmbKyMo0bN05r1qzRkiVL9NVXX2nkyJH6/PPPfQ9N+rJaemv6wf82kGg0SWUGAAAXor4HcCx/+9vfGn0/Z84cFRYWat26dTr//PM9jeqQtc9Jb/6X9D8zpO+Mk867RcrrEDaarKs3MsYoEon4HScAAC1cWldmDlddfbAK0rFjxyZfU1tbq5qamkaPZvHN/lLnbx2szCyfKs0YKC2bqpzaRKWG6gwAAM0vYozJiH9xjTG64oortHv3br311ltNvm7y5MmaMmXKEcerq6vVvn17u4Oqr5PeWyCV/bf08eaD48xpp1n7RmhBXYn+z+Ce6tg2R+3zclSQl6P2eTHl50aVdYLVmmT/gI7+KU1Xixr+Khz1Mw89HznKsyb4tEikwScbyRhlqV4y5uBTwVvDIUQOvvfw9zX4PJmjrD9q+GsbiUiRLCkSUSSSlfi6wRVoyQWylnxuADJDm/yOKuj4Tas/s6amRgUFBcf173fGhJlx48Zp0aJFWrlypbp3797k62pra1VbWxt+X1NTo+Li4uYJM4H6eun//lkqe0r6f+82z2cAAJCmVheN0ZCbZ1r9mScSZtJ6zUzgjjvu0MKFC7VixYpjBhlJisfjisfjjkZ2SFaWNOAKqf9lUsXr2vv3pxT7dOuh4oFp8F9z8L9N1EyacrRKyNe/p+mKzol+fsP3mMO+P/hZQcWm4dcHz9McOhJ+bSJSJKzHhD8x+L7hmBuPM/HqxDsj4SdEJEVMvSKSslSf1DVrSiSJPzPbXIzh665ZMr+3tsac7J+ni//XknUiYwvGlcx7TlQ6X7Nk+D4f359vW5PnkxVzO5DDpHWYMcbojjvu0Guvvably5erd+/evod0bFlZUv9Ratd/lO+RAADgzBDPn5/WYWbcuHF65ZVX9Kc//Un5+fnatWuXJKmgoEB5eXmeRwcAANJBWq+ZaWqh6pw5c3TjjTce1884kTk3AACQHlrMmpk0zlkAACBNZNR9ZgAAAA5HmAEAABmNMAMAADIaYQYAAGQ0wgwAAMhohBkAAJDRCDMAACCjEWYAAEBGI8wAAICMRpgBAAAZjTADAAAyWlr3ZrIh6O9UU1PjeSQAAOB4Bf9uH0+fxhYfZvbs2SNJKi4u9jwSAABwovbs2aOCgoJjviZiWnhr6vr6en300UfKz89XJBKx+rNrampUXFysysrKr21P3hJx/q37/CWuQWs/f4lrwPk33/kbY7Rnzx4VFRUpK+vYq2JafGUmKytL3bt3b9bPaN++fav8JQ5w/q37/CWuQWs/f4lrwPk3z/l/XUUmwAJgAACQ0QgzAAAgoxFmUhCPx/Xoo48qHo/7HooXnH/rPn+Ja9Daz1/iGnD+6XH+LX4BMAAAaNmozAAAgIxGmAEAABmNMAMAADIaYQYAAGQ0wkySfv3rX6t3797Kzc3VOeeco7feesv3kJrNihUrdNlll6moqEiRSEQLFixo9LwxRpMnT1ZRUZHy8vI0fPhwbdq0yc9gm0FpaanOPfdc5efnq7CwUFdeeaW2bNnS6DUt+RrMnj1bAwcODG+KNWTIEL3++uvh8y353I+mtLRUkUhEd955Z3ispV+DyZMnKxKJNHp07do1fL6ln78kffjhh7r++uvVqVMntWnTRmeeeabWrVsXPt/Sr0GvXr2O+B2IRCIaN26cpDQ4f4MTNm/ePBOLxczzzz9v3nvvPTNhwgTTtm1bs3PnTt9DaxZ//etfzYMPPmjmz59vJJnXXnut0fPTpk0z+fn5Zv78+aa8vNxcffXVplu3bqampsbPgC377ne/a+bMmWPeffdds3HjRjNq1CjTo0cPs3fv3vA1LfkaLFy40CxatMhs2bLFbNmyxUyaNMnEYjHz7rvvGmNa9rkfbu3ataZXr15m4MCBZsKECeHxln4NHn30UXPaaaeZ//znP+GjqqoqfL6ln/+nn35qevbsaW688Ubzj3/8w+zYscMsXbrUbNu2LXxNS78GVVVVjf78lyxZYiSZZcuWGWP8nz9hJgnf/va3za233troWP/+/c3999/vaUTuHB5m6uvrTdeuXc20adPCY19++aUpKCgwzz77rIcRNr+qqiojyZSVlRljWuc1+MY3vmF+85vftKpz37Nnj+nXr59ZsmSJueCCC8Iw0xquwaOPPmoGDRp01Odaw/nfd999ZtiwYU0+3xquweEmTJhg+vTpY+rr69Pi/JlmOkH79+/XunXrNHLkyEbHR44cqVWrVnkalT87duzQrl27Gl2PeDyuCy64oMVej+rqaklSx44dJbWua1BXV6d58+bp888/15AhQ1rVuY8bN06jRo3SiBEjGh1vLddg69atKioqUu/evXXNNddo+/btklrH+S9cuFCDBw/WD3/4QxUWFuqss87S888/Hz7fGq5BQ/v379fLL7+ssWPHKhKJpMX5E2ZO0P/+7/+qrq5OXbp0aXS8S5cu2rVrl6dR+ROcc2u5HsYYTZw4UcOGDdPpp58uqXVcg/LycrVr107xeFy33nqrXnvtNQ0YMKBVnLskzZs3T+vXr1dpaekRz7WGa3DeeefppZde0htvvKHnn39eu3bt0tChQ/XJJ5+0ivPfvn27Zs+erX79+umNN97QrbfeqvHjx+ull16S1Dp+BxpasGCBPvvsM914442S0uP8W3zX7OYSiUQafW+MOeJYa9Jarsftt9+uf/3rX1q5cuURz7Xka3DKKado48aN+uyzzzR//nyNGTNGZWVl4fMt+dwrKys1YcIELV68WLm5uU2+riVfg0suuST8+owzztCQIUPUp08fzZ07V9/5zncktezzr6+v1+DBgzV16lRJ0llnnaVNmzZp9uzZuuGGG8LXteRr0NALL7ygSy65REVFRY2O+zx/KjMnqHPnzsrOzj4ibVZVVR2RSluDYEdDa7ged9xxhxYuXKhly5ape/fu4fHWcA1ycnLUt29fDR48WKWlpRo0aJB++ctftopzX7dunaqqqnTOOecoGo0qGo2qrKxMM2fOVDQaDc+zJV+Dw7Vt21ZnnHGGtm7d2ip+B7p166YBAwY0Onbqqafqgw8+kNQ6/g4I7Ny5U0uXLtVNN90UHkuH8yfMnKCcnBydc845WrJkSaPjS5Ys0dChQz2Nyp/evXura9euja7H/v37VVZW1mKuhzFGt99+u/74xz/qzTffVO/evRs93xquweGMMaqtrW0V537RRRepvLxcGzduDB+DBw/Wddddp40bN+rkk09u8dfgcLW1tdq8ebO6devWKn4HSkpKjrgdQ0VFhXr27Cmpdf0dMGfOHBUWFmrUqFHhsbQ4fyfLjFuYYGv2Cy+8YN577z1z5513mrZt25p///vfvofWLPbs2WM2bNhgNmzYYCSZ6dOnmw0bNoRb0adNm2YKCgrMH//4R1NeXm6uvfbaFrUl8ac//akpKCgwy5cvb7Q1cd++feFrWvI1eOCBB8yKFSvMjh07zL/+9S8zadIkk5WVZRYvXmyMadnn3pSGu5mMafnX4O677zbLly8327dvN2vWrDGjR482+fn54d95Lf38165da6LRqHniiSfM1q1bzW9/+1vTpk0b8/LLL4evaenXwBhj6urqTI8ePcx99913xHO+z58wk6RnnnnG9OzZ0+Tk5Jizzz473KbbEi1btsxIOuIxZswYY8zBbYmPPvqo6dq1q4nH4+b888835eXlfgdt0dHOXZKZM2dO+JqWfA3Gjh0b/q5/85vfNBdddFEYZIxp2efelMPDTEu/BsE9Q2KxmCkqKjLf//73zaZNm8LnW/r5G2PMn//8Z3P66aebeDxu+vfvb5577rlGz7eGa/DGG28YSWbLli1HPOf7/CPGGOOmBgQAAGAfa2YAAEBGI8wAAICMRpgBAAAZjTADAAAyGmEGAABkNMIMAADIaIQZAACQ0QgzAAAgoxFmALQ6y5cvVyQS0WeffeZ7KAAsIMwAAICMRpgBAAAZjTADwDljjJ566imdfPLJysvL06BBg/SHP/xBUmIKaNGiRRo0aJByc3N13nnnqby8vNHPmD9/vk477TTF43H16tVLP//5zxs9X1tbq3vvvVfFxcWKx+Pq16+fXnjhhUavWbdunQYPHqw2bdpo6NCh2rJlS/OeOIBmQZgB4NxDDz2kOXPmaPbs2dq0aZPuuusuXX/99SorKwtfc8899+jpp5/W22+/rcLCQl1++eU6cOCApIMh5KqrrtI111yj8vJyTZ48WQ8//LBefPHF8P033HCD5s2bp5kzZ2rz5s169tln1a5du0bjePDBB/Xzn/9c77zzjqLRqMaOHevk/AHYRddsAE59/vnn6ty5s958800NGTIkPH7TTTdp3759uvnmm3XhhRdq3rx5uvrqqyVJn376qbp3764XX3xRV111la677jp9/PHHWrx4cfj+e++9V4sWLdKmTZtUUVGhU045RUuWLNGIESOOGMPy5ct14YUXaunSpbroooskSX/96181atQoffHFF8rNzW3mqwDAJiozAJx677339OWXX+riiy9Wu3btwsdLL72k999/P3xdw6DTsWNHnXLKKdq8ebMkafPmzSopKWn0c0tKSrR161bV1dVp48aNys7O1gUXXHDMsQwcODD8ulu3bpKkqqqqlM8RgFtR3wMA0LrU19dLkhYtWqSTTjqp0XPxeLxRoDlcJBKRdHDNTfB1oGGROS8v77jGEovFjvjZwfgAZA4qMwCcGjBggOLxuD744AP17du30aO4uDh83Zo1a8Kvd+/erYqKCvXv3z/8GStXrmz0c1etWqVvfetbys7O1hlnnKH6+vpGa3AAtFxUZgA4lZ+fr5/97Ge66667VF9fr2HDhqmmpkarVq1Su3bt1LNnT0nSY489pk6dOqlLly568MEH1blzZ1155ZWSpLvvvlvnnnuuHn/8cV199dVavXq1Zs2apV//+teSpF69emnMmDEaO3asZs6cqUGDBmnnzp2qqqrSVVdd5evUATQTwgwA5x5//HEVFhaqtLRU27dvV4cOHXT22Wdr0qRJ4TTPtGnTNGHCBG3dulWDBg3SwoULlZOTI0k6++yz9fvf/16PPPKIHn/8cXXr1k2PPfaYbrzxxvAzZs+erUmTJum2227TJ598oh49emjSpEk+ThdAM2M3E4C0Euw02r17tzp06OB7OAAyAGtmAABARiPMAACAjMY0EwAAyGhUZgAAQEYjzAAAgIxGmAEAABmNMAMAADIaYQYAAGQ0wgwAAMhohBkAAJDRCDMAACCj/X+nGNjxPKft5QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
