{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import models, regularizers, optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51328 images belonging to 7 classes.\n",
      "Found 10999 images belonging to 7 classes.\n",
      "Found 10999 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dir = \"../데이터셋/한국인 감정인식을 위한 복합 영상/최종데이터셋/train\"\n",
    "val_dir = \"../데이터셋/한국인 감정인식을 위한 복합 영상/최종데이터셋/val\"\n",
    "test_dir = \"../데이터셋/한국인 감정인식을 위한 복합 영상/최종데이터셋/test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127,975,239\n",
      "Trainable params: 127,975,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential(name=\"vgg16\")\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01), input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(2048, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"saved_models/vgg16_best_model.hdf5\"\n",
    "checkpoint_cb = ModelCheckpoint(checkpoint_path, verbose=1, save_best_only=True,monitor='val_loss')\n",
    "early_stop_cb = EarlyStopping(patience=15,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(learning_rate=2e-5), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 44.9256 - acc: 0.4493\n",
      "Epoch 1: val_loss improved from inf to 23.18954, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 626s 376ms/step - loss: 44.9256 - acc: 0.4493 - val_loss: 23.1895 - val_acc: 0.5718\n",
      "Epoch 2/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 16.3549 - acc: 0.6231\n",
      "Epoch 2: val_loss improved from 23.18954 to 11.88567, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 608s 379ms/step - loss: 16.3549 - acc: 0.6231 - val_loss: 11.8857 - val_acc: 0.6448\n",
      "Epoch 3/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 9.6112 - acc: 0.6802\n",
      "Epoch 3: val_loss improved from 11.88567 to 7.91226, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 611s 381ms/step - loss: 9.6112 - acc: 0.6802 - val_loss: 7.9123 - val_acc: 0.6716\n",
      "Epoch 4/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 6.7200 - acc: 0.7237\n",
      "Epoch 4: val_loss improved from 7.91226 to 5.88014, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 608s 379ms/step - loss: 6.7200 - acc: 0.7237 - val_loss: 5.8801 - val_acc: 0.6919\n",
      "Epoch 5/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 5.0960 - acc: 0.7576\n",
      "Epoch 5: val_loss improved from 5.88014 to 4.65000, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 615s 383ms/step - loss: 5.0960 - acc: 0.7576 - val_loss: 4.6500 - val_acc: 0.7243\n",
      "Epoch 6/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 4.0570 - acc: 0.7935\n",
      "Epoch 6: val_loss improved from 4.65000 to 3.84492, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 608s 379ms/step - loss: 4.0570 - acc: 0.7935 - val_loss: 3.8449 - val_acc: 0.7381\n",
      "Epoch 7/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 3.3354 - acc: 0.8266\n",
      "Epoch 7: val_loss improved from 3.84492 to 3.31707, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 607s 379ms/step - loss: 3.3354 - acc: 0.8266 - val_loss: 3.3171 - val_acc: 0.7400\n",
      "Epoch 8/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 2.8047 - acc: 0.8555\n",
      "Epoch 8: val_loss improved from 3.31707 to 2.96805, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 608s 379ms/step - loss: 2.8047 - acc: 0.8555 - val_loss: 2.9681 - val_acc: 0.7334\n",
      "Epoch 9/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 2.3894 - acc: 0.8817\n",
      "Epoch 9: val_loss improved from 2.96805 to 2.69750, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 608s 379ms/step - loss: 2.3894 - acc: 0.8817 - val_loss: 2.6975 - val_acc: 0.7362\n",
      "Epoch 10/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 2.0603 - acc: 0.9043\n",
      "Epoch 10: val_loss improved from 2.69750 to 2.50317, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 605s 377ms/step - loss: 2.0603 - acc: 0.9043 - val_loss: 2.5032 - val_acc: 0.7392\n",
      "Epoch 11/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.7869 - acc: 0.9221\n",
      "Epoch 11: val_loss improved from 2.50317 to 2.44864, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 606s 378ms/step - loss: 1.7869 - acc: 0.9221 - val_loss: 2.4486 - val_acc: 0.7255\n",
      "Epoch 12/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.5653 - acc: 0.9361\n",
      "Epoch 12: val_loss improved from 2.44864 to 2.30767, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 605s 377ms/step - loss: 1.5653 - acc: 0.9361 - val_loss: 2.3077 - val_acc: 0.7452\n",
      "Epoch 13/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.3811 - acc: 0.9466\n",
      "Epoch 13: val_loss improved from 2.30767 to 2.29772, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 595s 371ms/step - loss: 1.3811 - acc: 0.9466 - val_loss: 2.2977 - val_acc: 0.7290\n",
      "Epoch 14/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.2276 - acc: 0.9537\n",
      "Epoch 14: val_loss improved from 2.29772 to 1.99615, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 583s 363ms/step - loss: 1.2276 - acc: 0.9537 - val_loss: 1.9961 - val_acc: 0.7425\n",
      "Epoch 15/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1.0961 - acc: 0.9592\n",
      "Epoch 15: val_loss did not improve from 1.99615\n",
      "1604/1604 [==============================] - 579s 361ms/step - loss: 1.0961 - acc: 0.9592 - val_loss: 1.9978 - val_acc: 0.7393\n",
      "Epoch 16/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.9850 - acc: 0.9632\n",
      "Epoch 16: val_loss improved from 1.99615 to 1.90088, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 581s 362ms/step - loss: 0.9850 - acc: 0.9632 - val_loss: 1.9009 - val_acc: 0.7347\n",
      "Epoch 17/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.8901 - acc: 0.9650\n",
      "Epoch 17: val_loss did not improve from 1.90088\n",
      "1604/1604 [==============================] - 592s 369ms/step - loss: 0.8901 - acc: 0.9650 - val_loss: 1.9696 - val_acc: 0.6878\n",
      "Epoch 18/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.8081 - acc: 0.9691\n",
      "Epoch 18: val_loss improved from 1.90088 to 1.80287, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 584s 364ms/step - loss: 0.8081 - acc: 0.9691 - val_loss: 1.8029 - val_acc: 0.7350\n",
      "Epoch 19/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.7357 - acc: 0.9706\n",
      "Epoch 19: val_loss did not improve from 1.80287\n",
      "1604/1604 [==============================] - 579s 361ms/step - loss: 0.7357 - acc: 0.9706 - val_loss: 1.9404 - val_acc: 0.7282\n",
      "Epoch 20/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.6749 - acc: 0.9720\n",
      "Epoch 20: val_loss improved from 1.80287 to 1.54543, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 584s 364ms/step - loss: 0.6749 - acc: 0.9720 - val_loss: 1.5454 - val_acc: 0.7336\n",
      "Epoch 21/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.6197 - acc: 0.9735\n",
      "Epoch 21: val_loss improved from 1.54543 to 1.49813, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 584s 364ms/step - loss: 0.6197 - acc: 0.9735 - val_loss: 1.4981 - val_acc: 0.7380\n",
      "Epoch 22/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.5726 - acc: 0.9743\n",
      "Epoch 22: val_loss did not improve from 1.49813\n",
      "1604/1604 [==============================] - 579s 361ms/step - loss: 0.5726 - acc: 0.9743 - val_loss: 1.6358 - val_acc: 0.7401\n",
      "Epoch 23/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.5274 - acc: 0.9764\n",
      "Epoch 23: val_loss did not improve from 1.49813\n",
      "1604/1604 [==============================] - 579s 361ms/step - loss: 0.5274 - acc: 0.9764 - val_loss: 1.7576 - val_acc: 0.7146\n",
      "Epoch 24/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.4918 - acc: 0.9770\n",
      "Epoch 24: val_loss did not improve from 1.49813\n",
      "1604/1604 [==============================] - 578s 360ms/step - loss: 0.4918 - acc: 0.9770 - val_loss: 2.2427 - val_acc: 0.7211\n",
      "Epoch 25/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.4619 - acc: 0.9766\n",
      "Epoch 25: val_loss did not improve from 1.49813\n",
      "1604/1604 [==============================] - 578s 360ms/step - loss: 0.4619 - acc: 0.9766 - val_loss: 1.7337 - val_acc: 0.7304\n",
      "Epoch 26/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.4322 - acc: 0.9783\n",
      "Epoch 26: val_loss did not improve from 1.49813\n",
      "1604/1604 [==============================] - 578s 360ms/step - loss: 0.4322 - acc: 0.9783 - val_loss: 1.8032 - val_acc: 0.7315\n",
      "Epoch 27/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.4069 - acc: 0.9790\n",
      "Epoch 27: val_loss improved from 1.49813 to 1.49222, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 579s 361ms/step - loss: 0.4069 - acc: 0.9790 - val_loss: 1.4922 - val_acc: 0.7189\n",
      "Epoch 28/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.3869 - acc: 0.9785\n",
      "Epoch 28: val_loss did not improve from 1.49222\n",
      "1604/1604 [==============================] - 578s 360ms/step - loss: 0.3869 - acc: 0.9785 - val_loss: 1.5391 - val_acc: 0.7101\n",
      "Epoch 29/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.3658 - acc: 0.9799\n",
      "Epoch 29: val_loss did not improve from 1.49222\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.3658 - acc: 0.9799 - val_loss: 1.7780 - val_acc: 0.7326\n",
      "Epoch 30/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.3509 - acc: 0.9795\n",
      "Epoch 30: val_loss did not improve from 1.49222\n",
      "1604/1604 [==============================] - 577s 360ms/step - loss: 0.3509 - acc: 0.9795 - val_loss: 1.6377 - val_acc: 0.7295\n",
      "Epoch 31/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.3360 - acc: 0.9804\n",
      "Epoch 31: val_loss did not improve from 1.49222\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.3360 - acc: 0.9804 - val_loss: 1.8893 - val_acc: 0.7296\n",
      "Epoch 32/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.3251 - acc: 0.9804\n",
      "Epoch 32: val_loss improved from 1.49222 to 1.47533, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 577s 360ms/step - loss: 0.3251 - acc: 0.9804 - val_loss: 1.4753 - val_acc: 0.7263\n",
      "Epoch 33/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.3155 - acc: 0.9798\n",
      "Epoch 33: val_loss improved from 1.47533 to 1.47024, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 580s 362ms/step - loss: 0.3155 - acc: 0.9798 - val_loss: 1.4702 - val_acc: 0.7328\n",
      "Epoch 34/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.3035 - acc: 0.9811\n",
      "Epoch 34: val_loss did not improve from 1.47024\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.3035 - acc: 0.9811 - val_loss: 1.6887 - val_acc: 0.7311\n",
      "Epoch 35/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2940 - acc: 0.9817\n",
      "Epoch 35: val_loss did not improve from 1.47024\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.2940 - acc: 0.9817 - val_loss: 1.6624 - val_acc: 0.7296\n",
      "Epoch 36/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2859 - acc: 0.9815\n",
      "Epoch 36: val_loss did not improve from 1.47024\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.2859 - acc: 0.9815 - val_loss: 1.5670 - val_acc: 0.7228\n",
      "Epoch 37/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2778 - acc: 0.9821\n",
      "Epoch 37: val_loss did not improve from 1.47024\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.2778 - acc: 0.9821 - val_loss: 2.0815 - val_acc: 0.7212\n",
      "Epoch 38/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2708 - acc: 0.9829\n",
      "Epoch 38: val_loss did not improve from 1.47024\n",
      "1604/1604 [==============================] - 575s 358ms/step - loss: 0.2708 - acc: 0.9829 - val_loss: 1.8319 - val_acc: 0.7065\n",
      "Epoch 39/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2650 - acc: 0.9831\n",
      "Epoch 39: val_loss improved from 1.47024 to 1.46180, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 577s 360ms/step - loss: 0.2650 - acc: 0.9831 - val_loss: 1.4618 - val_acc: 0.7150\n",
      "Epoch 40/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2598 - acc: 0.9826\n",
      "Epoch 40: val_loss improved from 1.46180 to 1.34118, saving model to saved_models\\vgg16_best_model.hdf5\n",
      "1604/1604 [==============================] - 577s 359ms/step - loss: 0.2598 - acc: 0.9826 - val_loss: 1.3412 - val_acc: 0.7320\n",
      "Epoch 41/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2524 - acc: 0.9840\n",
      "Epoch 41: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 358ms/step - loss: 0.2524 - acc: 0.9840 - val_loss: 1.5301 - val_acc: 0.7332\n",
      "Epoch 42/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2507 - acc: 0.9832\n",
      "Epoch 42: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.2507 - acc: 0.9832 - val_loss: 1.4338 - val_acc: 0.7246\n",
      "Epoch 43/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2444 - acc: 0.9839\n",
      "Epoch 43: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 358ms/step - loss: 0.2444 - acc: 0.9839 - val_loss: 1.6656 - val_acc: 0.7164\n",
      "Epoch 44/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2381 - acc: 0.9844\n",
      "Epoch 44: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 577s 360ms/step - loss: 0.2381 - acc: 0.9844 - val_loss: 1.7768 - val_acc: 0.7265\n",
      "Epoch 45/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2336 - acc: 0.9849\n",
      "Epoch 45: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 358ms/step - loss: 0.2336 - acc: 0.9849 - val_loss: 1.5365 - val_acc: 0.6939\n",
      "Epoch 46/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2281 - acc: 0.9856\n",
      "Epoch 46: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.2281 - acc: 0.9856 - val_loss: 1.7432 - val_acc: 0.7321\n",
      "Epoch 47/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2232 - acc: 0.9863\n",
      "Epoch 47: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 576s 359ms/step - loss: 0.2232 - acc: 0.9863 - val_loss: 1.7165 - val_acc: 0.7180\n",
      "Epoch 48/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2186 - acc: 0.9861\n",
      "Epoch 48: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 359ms/step - loss: 0.2186 - acc: 0.9861 - val_loss: 1.6122 - val_acc: 0.7290\n",
      "Epoch 49/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2146 - acc: 0.9873\n",
      "Epoch 49: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 359ms/step - loss: 0.2146 - acc: 0.9873 - val_loss: 1.7923 - val_acc: 0.7192\n",
      "Epoch 50/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2141 - acc: 0.9857\n",
      "Epoch 50: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 578s 360ms/step - loss: 0.2141 - acc: 0.9857 - val_loss: 1.6220 - val_acc: 0.7351\n",
      "Epoch 51/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2112 - acc: 0.9855\n",
      "Epoch 51: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 359ms/step - loss: 0.2112 - acc: 0.9855 - val_loss: 1.5509 - val_acc: 0.7238\n",
      "Epoch 52/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2045 - acc: 0.9872\n",
      "Epoch 52: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 359ms/step - loss: 0.2045 - acc: 0.9872 - val_loss: 1.7823 - val_acc: 0.7273\n",
      "Epoch 53/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2022 - acc: 0.9876\n",
      "Epoch 53: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 358ms/step - loss: 0.2022 - acc: 0.9876 - val_loss: 1.4529 - val_acc: 0.7282\n",
      "Epoch 54/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.2006 - acc: 0.9872\n",
      "Epoch 54: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 575s 358ms/step - loss: 0.2006 - acc: 0.9872 - val_loss: 1.3823 - val_acc: 0.7157\n",
      "Epoch 55/300\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.1960 - acc: 0.9874\n",
      "Epoch 55: val_loss did not improve from 1.34118\n",
      "1604/1604 [==============================] - 574s 358ms/step - loss: 0.1960 - acc: 0.9874 - val_loss: 1.5765 - val_acc: 0.7248\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=300,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[checkpoint_cb,early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 32s 91ms/step - loss: 1.3512 - acc: 0.7348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3511903285980225, 0.7347940802574158]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/HElEQVR4nO3de3xU9YH38e+Zey6TAAESAuEiN0UEBSwFbMEL7HqrPm5XW92uPm639dZK7ZZW2bZYd8GHbSl1UVy3XWuffVx0i5durS5YAWsRGxBWROQiCBEI4RJyTyaZOc8fZ2YykwQMyZk5M+Hzfr3Oa86cM5ffnExyvvndjmGapikAAIAs5XK6AAAAAL1BmAEAAFmNMAMAALIaYQYAAGQ1wgwAAMhqhBkAAJDVCDMAACCreZwuQKpFIhEdPnxYwWBQhmE4XRwAANANpmmqrq5OpaWlcrnOXPfS58PM4cOHVVZW5nQxAABAD1RUVGjYsGFnfEyfDzPBYFCSdTAKCgocLg0AAOiO2tpalZWVxc/jZ9Lnw0ysaamgoIAwAwBAlulOFxE6AAMAgKxGmAEAAFmNMAMAALIaYQYAAGQ1wgwAAMhqhBkAAJDVCDMAACCrEWYAAEBWI8wAAICsRpgBAABZjTADAACyGmEGAABktT5/oclUaWhpU3VjSH6PW4OCfqeLAwDAOYuamR76xVv7ddn/Wadla3c7XRQAAM5phJkeyvG6JUnNrWGHSwIAwLmNMNNDAZ8VZppChBkAAJxEmOmhWM1MEzUzAAA4ijDTQ4QZAAAyA2Gmh3J81qGjzwwAAM4izPRQwEufGQAAMgFhpodoZgIAIDMQZnoox8fQbAAAMgFhpodyaGYCACAjEGZ6KLGZyTRNh0sDAMC5izDTQ7FJ8yKmFApHHC4NAADnLsJMD8VqZiSpOUSYAQDAKYSZHvK6XfK4DEmMaAIAwEmEmV5geDYAAM4jzPRCgOHZAAA4jjDTC9TMAADgPMJML8TCTDNzzQAA4BjCTC/EmpmomQEAwDmEmV4IeKzDR5gBAMA5hJleiF2fiUsaAADgHMJML8T7zFAzAwCAYwgzvcBoJgAAnEeY6YV4B2AuZwAAgGMIM71AzQwAAM4jzPQCfWYAAHAeYaYXGM0EAIDzCDO9EKCZCQAAxxFmeoE+MwAAOI8w0ws5Puvw0WcGAADnEGZ6IV4zQ58ZAAAcQ5jpBfrMAADgPMJML9BnBgAA5xFmeiE2NLuZZiYAAByTMWFmyZIlMgxD8+fPj28zTVOLFi1SaWmpcnJyNGfOHO3YscO5QnZAzQwAAM7LiDBTXl6up556SpMmTUravnTpUi1btkwrVqxQeXm5SkpKNHfuXNXV1TlU0mT0mQEAwHmOh5n6+nrddttt+td//Vf1798/vt00TS1fvlwLFy7UTTfdpIkTJ+qZZ55RY2Ojnn32WQdL3C7ezNQaUSRiOlwaAADOTY6HmXvvvVfXXnutrrrqqqTt+/fvV2VlpebNmxff5vf7NXv2bG3cuPG0r9fS0qLa2tqkJVVizUyS1NLGlbMBAHCCx8k3X7Vqld59912Vl5d32ldZWSlJKi4uTtpeXFysAwcOnPY1lyxZoocfftjegp5GICHMNLWG4zU1AAAgfRyrmamoqND999+vf//3f1cgEDjt4wzDSLpvmmanbYkefPBB1dTUxJeKigrbytyR22XI52EWYAAAnORYzcyWLVtUVVWlqVOnxreFw2G9+eabWrFihXbt2iXJqqEZMmRI/DFVVVWdamsS+f1++f3+1BW8gxyvW6G2CJ2AAQBwiGM1M1deeaW2b9+ubdu2xZdp06bptttu07Zt23TeeeeppKREa9eujT8nFAppw4YNmjlzplPF7oRLGgAA4CzHamaCwaAmTpyYtC0vL09FRUXx7fPnz9fixYs1duxYjR07VosXL1Zubq5uvfVWJ4rcpfYRTYQZAACc4GgH4E+zYMECNTU16Z577lF1dbWmT5+uNWvWKBgMOl20OOaaAQDAWRkVZtavX5903zAMLVq0SIsWLXKkPN0R8FotdTQzAQDgDMfnmcl2XNIAAABnEWZ6KRZm6DMDAIAzCDO9FPAxmgkAACcRZnqpvZmJyxkAAOAEwkwv0WcGAABnEWZ6iXlmAABwFmGmlwLMAAwAgKMIM71EMxMAAM4izPRSTmzSPMIMAACOIMz0UrzPDM1MAAA4gjDTS1ybCQAAZxFmeok+MwAAOIsw00s5zAAMAICjCDO9xLWZAABwFmGml+gzAwCAswgzvUQzEwAAziLM9FJ7MxMXmgQAwAmEmV6KhZlQOKJwxHS4NAAAnHsIM70Ua2aS6AQMAIATCDO95Pe0H0I6AQMAkH6EmV4yDKN94jw6AQMAkHaEGRvEr89EzQwAAGlHmLEBlzQAAMA5hBkbBLzWYaSZCQCA9CPM2IBZgAEAcA5hxgZcnwkAAOcQZmwQv6QBYQYAgLQjzNgg3swU4pIGAACkG2HGBoxmAgDAOYQZG9BnBgAA5xBmbBDvM8PQbAAA0o4wYwOGZgMA4BzCjA3oMwMAgHMIMzbI8VmHsZlmJgAA0o4wYwNqZgAAcA5hxgb0mQEAwDmEGRswmgkAAOcQZmzAPDMAADiHMGMD+swAAOAcwowNAlxoEgAAxxBmbJDDhSYBAHAMYcYG9JkBAMA5hBkbxEYzEWYAAEg/wowNYvPMtEVMtYZpagIAIJ0IMzaINTNJdAIGACDdCDM28LoNuV2GJK7PBABAuhFmbGAYBnPNAADgEMKMTbg+EwAAziDM2CTHZx1Krs8EAEB6EWZsEvBQMwMAgBMIMzZhrhkAAJxBmLFJgEsaAADgCMKMTRjNBACAMwgzNiHMAADgDMKMTeJ9ZhjNBABAWhFmbMI8MwAAOIMwYxOamQAAcAZhxiZMmgcAgDMIMzaJ1cwwzwwAAOlFmLEJfWYAAHAGYcYmsdFMNDMBAJBehBmb0AEYAABnEGZsQp8ZAACcQZixScBHzQwAAE5wNMysXLlSkyZNUkFBgQoKCjRjxgy9+uqr8f2maWrRokUqLS1VTk6O5syZox07djhY4tOLNzPRZwYAgLRyNMwMGzZMjz76qDZv3qzNmzfriiuu0A033BAPLEuXLtWyZcu0YsUKlZeXq6SkRHPnzlVdXZ2Txe5SezMTV80GACCdHA0z119/va655hqNGzdO48aN0z/+4z8qPz9fmzZtkmmaWr58uRYuXKibbrpJEydO1DPPPKPGxkY9++yzTha7S/FrM9HMBABAWmVMn5lwOKxVq1apoaFBM2bM0P79+1VZWal58+bFH+P3+zV79mxt3LjxtK/T0tKi2trapCUdGM0EAIAzHA8z27dvV35+vvx+v+666y69+OKLmjBhgiorKyVJxcXFSY8vLi6O7+vKkiVLVFhYGF/KyspSWv6YxEnzTNNMy3sCAIAMCDPjx4/Xtm3btGnTJt199926/fbb9cEHH8T3G4aR9HjTNDttS/Tggw+qpqYmvlRUVKSs7IlizUymKbW00W8GAIB08ThdAJ/PpzFjxkiSpk2bpvLycv3sZz/Td7/7XUlSZWWlhgwZEn98VVVVp9qaRH6/X36/P7WF7kLA054Lm1vD8ZoaAACQWo7XzHRkmqZaWlo0atQolZSUaO3atfF9oVBIGzZs0MyZMx0sYdc8bpd87uiVs+k3AwBA2jhaM/PQQw/p6quvVllZmerq6rRq1SqtX79er732mgzD0Pz587V48WKNHTtWY8eO1eLFi5Wbm6tbb73VyWKfVsDrUigcYa4ZAADSyNEwc/ToUX3lK1/RkSNHVFhYqEmTJum1117T3LlzJUkLFixQU1OT7rnnHlVXV2v69Olas2aNgsGgk8U+rRyfW7XNbdTMAACQRobZx4fe1NbWqrCwUDU1NSooKEjpe83+p3U6cKJRq++eoakjBqT0vQAA6MvO5vydcX1msln7JQ0YzQQAQLoQZmwUYOI8AADSjjBjI2YBBgAg/QgzNopfn4nRTAAApA1hxkbUzAAAkH6EGRvRZwYAgPQjzNgoxxedAZhmJgAA0oYwY6NYM1MzNTMAAKQNYcZG9JkBACD9CDM2Cvhik+YRZgAASBfCjI2omQEAIP0IMzaizwwAAOlHmLFRbNI8amYAAEgfwoyN4vPM0GcGAIC0IczYqL3PDFfNBgAgXQgzNoo1M7XQzAQAQNoQZmzEaCYAANKPMGMjrs0EAED6EWZslMOkeQAApB1hxkaxZqaWtogiEdPh0gAAcG4gzNgoFmYkqbmN2hkAANKBMGMjv6f9cNLUBABAehBmbORyGQp4rUNKJ2AAANKDMGMzrs8EAEB6EWZs1n5JA2YBBgAgHQgzNmPiPAAA0oswYzMmzgMAIL0IMzZj4jwAANKLMGMzOgADAJBehBmb0cwEAEB6EWZsRjMTAADpRZixWQ6T5gEAkFaEGZvRZwYAgPQizNgsQDMTAABpRZixGZPmAQCQXoQZmxFmAABIL8KMzWKjmegzAwBAehBmbNZ+oUnCDAAA6UCYsRnNTAAApBdhxmbtYSbicEkAADg39CjMPPPMM3rllVfi9xcsWKB+/fpp5syZOnDggG2Fy0axPjMt1MwAAJAWPQozixcvVk5OjiTp7bff1ooVK7R06VINHDhQ3/rWt2wtYLbh2kwAAKSXpydPqqio0JgxYyRJL730kr74xS/qa1/7mmbNmqU5c+bYWb6sk0MHYAAA0qpHNTP5+fk6ceKEJGnNmjW66qqrJEmBQEBNTU32lS6Tlf9c+udp0hv/mLQ5fqFJamYAAEiLHtXMzJ07V1/96ld1ySWXaPfu3br22mslSTt27NDIkSPtLF/mam2STuyRTu5L2sy1mQAASK8e1cw8/vjjmjFjho4dO6bVq1erqKhIkrRlyxZ9+ctftrWAGSu/xLqtP5q0ORZmWsOmWsOMaAIAINV6VDPTr18/rVixotP2hx9+uNcFyhrBaJipq0zaHPC158Pm1rC8bka/AwCQSj0607722mt666234vcff/xxXXzxxbr11ltVXV1tW+Ey2mnCjM/tksuw1uk3AwBA6vUozHznO99RbW2tJGn79u369re/rWuuuUb79u3TAw88YGsBM1Z+sXUbqpNCDfHNhmG095sJ0cwEAECq9aiZaf/+/ZowYYIkafXq1bruuuu0ePFivfvuu7rmmmtsLWDG8gclb67U2mjVzhSNju8KeN1qCIWpmQEAIA16VDPj8/nU2NgoSXr99dc1b948SdKAAQPiNTZ9nmG018506ATMxHkAAKRPj2pmLrvsMj3wwAOaNWuW/vSnP+m5556TJO3evVvDhg2ztYAZLVgiVe/v1G8mPtcME+cBAJByPaqZWbFihTwej379619r5cqVGjp0qCTp1Vdf1Z//+Z/bWsCMFjzz8GzmmgEAIPV6VDMzfPhw/fa3v+20/ac//WmvC5RVYnPN1B1J2pxDMxMAAGnTozAjSeFwWC+99JJ27twpwzB0wQUX6IYbbpDb7bazfJktGO0zU9ehzwzNTAAApE2PwszevXt1zTXX6NChQxo/frxM09Tu3btVVlamV155RaNHj/70F+kL4rMAd+gz47Va76iZAQAg9XrUZ+ab3/ymRo8erYqKCr377rvaunWrDh48qFGjRumb3/ym3WXMXKepmaHPDAAA6dOjmpkNGzZo06ZNGjBgQHxbUVGRHn30Uc2aNcu2wmW809XM0MwEAEDa9Khmxu/3q66urtP2+vp6+Xy+Xhcqa8RGMzVVS20t8c3MMwMAQPr0KMxcd911+trXvqZ33nlHpmnKNE1t2rRJd911l77whS/YXcbMldNfcvut9YS5ZhjNBABA+vQozDz22GMaPXq0ZsyYoUAgoEAgoJkzZ2rMmDFavny5zUXMYKeZBZg+MwAApE+P+sz069dPL7/8svbu3audO3fKNE1NmDBBY8aMsbt8mS9YLNUcTK6Zoc8MAABp0+0w82lXw16/fn18fdmyZT0uUNbpomaGPjMAAKRPt8PM1q1bu/U4wzB6XJisFBxi3XbZZybiRIkAADindDvMrFu3LpXlyF7xuWY6NzPRZwYAgNTrUQdguyxZskSXXnqpgsGgBg8erBtvvFG7du1Keoxpmlq0aJFKS0uVk5OjOXPmaMeOHQ6VuAtdzDVDB2AAANLH0TCzYcMG3Xvvvdq0aZPWrl2rtrY2zZs3Tw0NDfHHLF26VMuWLdOKFStUXl6ukpISzZ07t8t5bhwRm2umros+M3QABgAg5Xp8oUk7vPbaa0n3n376aQ0ePFhbtmzR5z//eZmmqeXLl2vhwoW66aabJEnPPPOMiouL9eyzz+rrX/96p9dsaWlRS0v7BHa1tbWp/RDxDsBdjGaiZgYAgJRztGamo5qaGkmKXyZh//79qqys1Lx58+KP8fv9mj17tjZu3NjlayxZskSFhYXxpaysLLWFjtXMNByXwm2SaGYCACCdMibMmKapBx54QJdddpkmTpwoSaqstGo7iouLkx5bXFwc39fRgw8+qJqamvhSUVGR2oLnDpQMtyRTaqiSlDCaiWYmAABSztFmpkT33Xef3nvvPb311lud9nUc7m2a5mmHgPv9fvn9/pSUsUsul9XUVHdYqjsiFZQq4LMyYlNr+IxlBQAAvZcRNTPf+MY39Jvf/Ebr1q3TsGHD4ttLSqwmnI61MFVVVZ1qaxwVH55tdQKO1cxETCkUZq4ZAABSydEwY5qm7rvvPr3wwgt64403NGrUqKT9o0aNUklJidauXRvfFgqFtGHDBs2cOTPdxT29DsOzY6OZJKk5RJgBACCVHG1muvfee/Xss8/q5ZdfVjAYjNfAFBYWKicnR4ZhaP78+Vq8eLHGjh2rsWPHavHixcrNzdWtt97qZNGTdaiZ8bpd8roNtYZNNbWGVSivg4UDAKBvczTMrFy5UpI0Z86cpO1PP/207rjjDknSggUL1NTUpHvuuUfV1dWaPn261qxZo2AwmObSnkEXE+cFvG61htsYng0AQIo5GmZM0/zUxxiGoUWLFmnRokWpL1BPnWbivLrmNkY0AQCQYhnRATjrxcPMkfimHK6cDQBAWhBm7BCfBbi9ZoaJ8wAASA/CjB1iNTP1VVLECi8BHxPnAQCQDoQZO+QNlmRIZlhqPCFJyvG2T5wHAABShzBjB7dHyhtkrddZI5roMwMAQHoQZuwSTO43E7tyNn1mAABILcKMXfKTRzQFuNgkAABpQZixy2muz0QzEwAAqUWYsUuHWYAJMwAApAdhxi7xifOiYSbWZ4ZmJgAAUoowY5f4XDNWM1OAmhkAANKCMGOX/OTrM7U3M0WcKhEAAOcEwoxd4kOzKyXTZGg2AABpQpixS+z6TOGQ1FTNtZkAAEgTwoxdPH4pp7+1XlfJPDMAAKQJYcZOwSHWbX1lvJmJDsAAAKQWYcZO+e0T5zHPDAAA6UGYsVOwfeK8eJ8ZmpkAAEgpwoyd4jUzlcrxWYeWmhkAAFKLMGOnhFmAc30eSVJ9S5vCEdPBQgEA0LcRZuwUq5mpP6rigoB8Hpdaw6Y+qW50tlwAAPRhhBk7xUYz1VXK7TI0elC+JGnP0XoHCwUAQN9GmLFTsL1mRqapsYOjYaaKMAMAQKoQZuwUuz5Ta6PUUpcQZuocLBQAAH0bYcZOvlzJX2Ct11VqbHFQkrSXmhkAAFKGMGO3/PYLTo4tbu8zE2FEEwAAKUGYsVt8ePZRjRiQK6/bUFNrWIdONTlbLgAA+ijCjN0SZgH2uF06b6BVO0NTEwAAqUGYsVvCLMCSNKaYTsAAAKQSYcZu8ZqZo5KkcYOtTsDMNQMAQGoQZuyW335JA0nxTsC7aWYCACAlCDN2CyY3M8Xmmtl7tE6myYgmAADsRpixW+ySBtFmphFFefK4DDWEwjpS0+xgwQAA6JsIM3aLdQBuqZVCjfJ5XBo5ME8SlzUAACAVCDN28wclb661Xm81NY2LT57HiCYAAOxGmLGbYXQens2IJgAAUoYwkwrBDiOauOAkAAApQ5hJhfj1maxOwPFrNFXVM6IJAACbEWZSITaiKVozM2pgntwuQ3XNbaqqa3GwYAAA9D2EmVQIJtfM+D1ujSiyOgXvphMwAAC2IsykQodZgKWEfjN0AgYAwFaEmVToMAuwJI2NjWhirhkAAGxFmEmFWM1MfUKYiXYC3suIJgAAbEWYSYXY0OymaqnN6vA7JtrMtPsoI5oAALATYSYVcvpLbp+1Hu0EPHpQvlyGVNPUqmP1jGgCAMAuhJlUMIyETsBWmAl43Ro+wBrRtJdOwAAA2IYwkyrx4dnt/WbG0AkYAADbEWZSJb+LEU3FXNYAAAC7EWZSJchcMwAApANhJlWCnYdnjyummQkAALsRZlKlQwdgyRrRZBjSyYaQTjCiCQAAWxBmUqWLmpkcn1vD+udIonYGAAC7EGZSpYsOwBKXNQAAwG6EmVTpP1IyXFLDManmk/jmWCfgvVw9GwAAWxBmUiVQIA271Frf+/v45rHRTsC7GdEEAIAtCDOpNPpK63bv6/FN8eHZNDMBAGALwkwqjbnKut23QQq3SZJGR8PM8foWVTeEnCoZAAB9BmEmlUovlnIGSC010qHNkqR8v0dD+1kjmvYeo3YGAIDeIsykksstjb7cWk9saope1mA3nYABAOg1wkyqxZqaEjsBc1kDAABsQ5hJtdFXWLeHt0oNxyW1zzWzl07AAAD0GmEm1YIlUvFFkkzpo3WSpDFcPRsAANsQZtJhTHSI9kdWU9OYaDPT0doW1TS1OlUqAAD6BMJMOsTCzN7fS5GICgJeDSkMWJuonQEAoFccDTNvvvmmrr/+epWWlsowDL300ktJ+03T1KJFi1RaWqqcnBzNmTNHO3bscKawvVH2WcmbJzVUSUe3S2qvnaETMAAAveNomGloaNDkyZO1YsWKLvcvXbpUy5Yt04oVK1ReXq6SkhLNnTtXdXVZVpvh8UmjPm+tR0c1ccFJAADs4XHyza+++mpdffXVXe4zTVPLly/XwoULddNNN0mSnnnmGRUXF+vZZ5/V17/+9S6f19LSopaWlvj92tpa+wveE2OulHa/aoWZzz0Qn2uGMAMAQO9kbJ+Z/fv3q7KyUvPmzYtv8/v9mj17tjZu3Hja5y1ZskSFhYXxpaysLB3F/XSxfjMVm6SWOq6eDQCATTI2zFRWVkqSiouLk7YXFxfH93XlwQcfVE1NTXypqKhIaTm7bcB51hJpk/a/GW9mOlzTrLpmRjQBANBTGRtmYgzDSLpvmmanbYn8fr8KCgqSlowRnw34dRXmejU46JdEUxMAAL2RsWGmpKREkjrVwlRVVXWqrckao2NDtF+XTFMThxZKktZ/WOVgoQAAyG4ZG2ZGjRqlkpISrV27Nr4tFAppw4YNmjlzpoMl64WRl0lun3TqoHTiI914yVBJ0q+3fKJwxHS4cAAAZCdHw0x9fb22bdumbdu2SbI6/W7btk0HDx6UYRiaP3++Fi9erBdffFHvv/++7rjjDuXm5urWW291stg958+Xhn/WWt/7uuZNKFZhjleHa5r1x73HnS0bAABZytEws3nzZl1yySW65JJLJEkPPPCALrnkEv3gBz+QJC1YsEDz58/XPffco2nTpunQoUNas2aNgsGgk8XunVi/mY9+r4DXrRsvLpUkPbc5QzoqAwCQZQzTNPt0+0Ztba0KCwtVU1OTGZ2Bj+6QVs6UPDnSdz/W+1Utuu6f35LP7dI7D12p/nk+p0sIAIDjzub8nbF9ZvqswROk4BCprUk6uFEThxbqwtIChcIRvbTtkNOlAwAg6xBm0s0wEkY1WZc2uHmaNbHfc+UV6uMVZQAA2I4w44QxV1i30TBzw8Wl8nlc+rCyTjsOZ8jlFwAAyBKEGSecd7lkuKRjO6WaT9Qv16c/u9CaV+e5cjoCAwBwNggzTsgdIA2daq1/9IYk6eZpwyRJL287pObWsFMlAwAg6xBmnJI4G7CkWaMHami/HNU2t+m/d5z+2lMAACAZYcYp8flm1kvhNrlchr441aqdeZ45ZwAA6DbCjFOGTpEC/aSWGungRknSX04bJsOQ/rj3hCpONjpbPgAAsgRhxikutzThBmt93RLJNDWsf65mjR4oSfrPLZ84WDgAALIHYcZJsxdInoBVM7PrVUnSzZdac878enMFF58EAKAbCDNOKhwmffZua/31H0rhNs2bUKyCgIeLTwIA0E2EGadd9i0pZ4B0fLe09f9aF5+8ZKgkOgIDANAdhBmnBQqt5iZJWr9EaqmPX95gzY6jOtUYcrBwAABkPsJMJpj2N1L/kVL9UentxzVxaKEmDIlefHIrF58EAOBMCDOZwOOTrvyBtf7Hn0n1Vbol2hH4+c2MagIA4EwIM5niwpuk0ilSa4O0/tH4xSc/OFKr9w/VOF06AAAyFmEmUxiGNO8Ra33LL9Wv8UD84pP/9sf9DhYMAIDMRpjJJCMvk8ZdLZlh6fVFumPmSEnSC+8e0roPq5wtGwAAGYowk2muWiQZLunD32qqsUt/c9koSdJ3V7+n6gZGNgEA0BFhJtMMPl+65CvW+prv6zvzxmnM4HxV1bXo+y+/72zZAADIQISZTDTnQcmbK33yJwX2/k7Lbp4st8vQb987ov/6n8NOlw4AgIxCmMlEBUOkGfdZ668v0qQhebr38jGSpO+//L6qapsdLBwAAJmFMJOpZn1Tyh0onfxI+tNT+sYVYzRxaIFONbbqu6vfk2lyEUoAACTCTObyB6XLH7LW13xf3r1rtOzmi+XzuLRu1zE9V851mwAAkAgzmW3andLkW62h2v95h8aFduo788ZLkh757QeqONnocAEBAHAeYSaTGYb0hceksfOktibp2Zt15/iQPjNygBpCYX37P/9HkQjNTQCAcxthJtO5vdJf/lIaOk1qqpb7//2Ffnr1IOX63PrT/pPMDgwAOOcRZrKBL0+69XmpaKxU+4mG/vav9PC8oZKkpf+9S3uO1jlcQAAAnEOYyRZ5RdJXXpCCQ6RjO/XF3d/R3LEFCrVF9M1V21TT2Op0CQEAcARhJpv0Gy791WrJXyjj4Nv6Z98KDcp1a+eRWt3y1NuqqmP+GQDAuYcwk22KL5S+/B+S26/AR69p7fiXNTjfpw8r6/SXT77NCCcAwDmHMJONRs6S/uLnkuFSv53Pau3k9Rre368DJxr1l0++rb1V9KEBAJw7CDPZasIXpGt+LEkq3LJCa4sf16UDW1VZ26y/fPJtvffJKWfLBwBAmhBmstmlfyNd/zPJE5D/4zf0XOTvdPvgj1Td2Kpb//Udbdp3wukSAgCQcoSZbDf1Dulv10mDJ8jVeEwP135fK4pWq6WlWbf/25/0+51HnS4hAAApRZjpC4onSH/7hnTp30qSrmtYrbUF/6Ah4UP6+v/dope3HXK4gAAApA5hpq/w5kjX/lj60rNSTn+NDO3Wfwf+Xjca6zX/ua360X99oMZQm9OlBADAdoSZvub8a6W7N0ojPye/2aQfe/9FP/Os0O/+uFl/tvxNvbXnuNMlBADAVoZpmn36SoW1tbUqLCxUTU2NCgoKnC5O+kTC0ls/ldYtlsywWuXR6rbL9GT4en1m6qVaeO0EFeZ4nS4lAABdOpvzN2Gmr/tks/T6IunjP0iSwqahVyPT9R/+L+qv/9f1+rMLS5wtHwAAXSDMJDjnw0zMwXekt5ZJu1+Lb1oXnqytI+7UV275sgYF/Q4WDgCAZISZBISZDirfV/gPy2TseFEuRSRJ7+p81U/8ij4z78sKFBQ5XEAAAAgzSQgzp3HiI51c+2MFP3xeXlmjnNrk1pH+0zRo2k0KTLxeKhzqcCEBAOcqwkwCwsyZtZ46pJ3/9TPl7/udzjMrkva1lVwiz4TrpAuulwaOkwzDoVICAM41hJkEhJnuaQ1H9MYf39aBPz6vKU0bNcXYI5eR8NXoP1IacZk0YqZ1oct+Iwg3AICUIcwkIMycnUjE1JoPKvX/fl+uoVUb9Geucs1y7ZDP6DDhXsFQacSsaLi5TCoaQ7gBANiGMJOAMNMzpmnqD3uO6/F1e/X+/kO61LVLn3F9qM/7dukCc6/cZjj5CbkDpZKJ0uALpcEXWJdYGHSB5Mt15gMAALIaYSYBYab3thyo1nPlB/XKe0fUEAoroBZNce3RXww4oM/5d2tQzXYZbc1dPNOQBoySBk+wlvzBki9f8uVJ/vzoeux+UPIXSG5P2j8fACDzEGYSEGbs0xhq02vvV2r1u59o40cnFPvmFPoi+t+j6zW36LjGGRXyHv9QqvpAajh2dm9guK0RVP1GRJfhUv/obb8RUrBEcrnt/2AAgIxDmElAmEmNT6ob9eK7h7T63U/08YnG+Hafx6UZ5xXpivMH66rhLg0N7beCTdVOqalaCtVLoQappT66Hr3fZc1OB4ZLcnmsW8NlhR/DZfXVMVxW0Bk4Xho9Rxp9hTTkYsJPqpyqkPa+LpVeLJVe4nRpAPRBhJkEhJnUMk1TWw5U67fvHdHvPzyqipNNSfvHFefrivOLdeUFg3VJWT953Ke5tmm41arJOXVQqj5g3Z76uP1+zSdSx346nyanvzRqtjT6civc9Bvesw8Ji2lKFX+SNj0h7fyv9p/HyM9Js+6XxlxFJ/BMVnfU+j0qniB5c5wuDfCpCDMJCDPpY5qmPjpWr9/vrNLvP6zSlgPVCkfav155Premjhyg6aMG6LPnDdBFQ/vJ5+nmhdvDbVLjcesCmmbEOpGaEesEG9sWbpE+KZc+Wiftf1NqqU1+jQGjrZoEwyUlfe0T1g2XlDNAyhsk5Q+ybvMGSXkDpbzBVv8eyapJaq6JLrXR21PWrWFY7zVwrBQccnYn+KZT1gknOETKy5DZmNtC0gcvWSHm8Nb27SWTrFq3SHSk2+AJ0sxvShP/QvL4HCkqunBsl/THx6T3npMirVbtZskkqewz1jLsM1LhMIIoMg5hJgFhxjk1ja3asOeY3th5VOt3H9Opxtak/QGvS1NH9Nf0UUWaPmqAJpf1U8BrU7NQuE06tEXat0766A3rgptnW7PTFU8gGpxC3Xu8N08qOk8qGmsNXy8aI/UrkxqOW7VONRXRWqiDVtNNS431PMNt1ShddLN0/rVWh+l0azgubX5aKv+5VF9pbXP7pUk3S5+9Wyq+0Apem1ZKW35pNRlKUrDU2j/1DinQxe9cW8gKms01VqgsGp15J9Kmaus7U/GOVRvlcksX3iRdeKPVWT0bHHxH+uNyadfv2rcF+lmhu6NgqVR2qVQ2XRr359bPBKkVbrN+B3IHpPb7b5qZ9/vVTYSZBISZzBCJmPqwsk7v7D+hd/ad1J8+PqmTDcmBwOMyNK44qIuGFmrisEJdNLRQ55cE7Qk4zTXSx29J1R9Liv5iJ/2CR9cjbVLTSam+yjqZNxyTGqqk+mNSW1OHFzWkQGHnJdwqndhrvVdPAlTHE443Vxp/jRUiRl8hub1n/5pdCbdZIaXmkFR7SKo9HF2i60f+x6rtkqT8EunSr0rT/rdVS9VR0ylp879J7zwp1R+1tvkLrP/8W+oSarFqpNbG5OfmF0ujr5TGXCmdd3nvaqTCrdLR960gcmiLdVv9sVXTFe9MPry9g3m/4da+6v3R4BINL8c+7Pr1vbnWjNiTv2w1Ybq6WbN4Ji31Vpnrj0pun/Xzdfs6r3v8Um6RNQLwdCenSETa89/SW8ulik3RjYYViGfNl4ZNswJ0xZ+iyztS5fbO39Pii6zgduH/yrxgE2q0fr/qKq3vb13icsQ6jg3HrZGUQ6dJw6ZKwy61poo402jJ5lrp6A7reBzdbjVvuzzWce/0M4luyy2yvr/5xdZozfxi6/cjsa9eW4tV3mO7rOV49PbEXuufIl++dYyLxlozrQ8c0/7Pz9lObdFSb/3eHn5XOvSu9TtQ84n1+cf9mRVUB1+QNeGGMJOAMJOZTNPU3qp6bdp/Uu/sO6F39p/UsbqWTo/zuAyNLQ7qoqEFumhoocYVBzW2OKgBeQ40Y4QarHBjuK3Q4ss/88ks3Gr9QTyxx/rDdXyPdOIj62SSNyjhxFrWfnItHGY1ZR3fK23/T2n789LJfe2vmVtknWDGX231CfLmWX/wYreeQPsfqtZm6w/ZqQOda4BOHbROBGbkzJ95yMXSjHulCTd2r+morUV673lp42PS8d1nfqy/wPpjntT527A6FI+5ygo3Q6cln4DaQlYYam20TmqtDdYxjQWXI9u615m8OwaMbm+KaaqWtv2H9bOMKRgmTb5FmnyrdQLqjuYa6ch71gnnyP9Y5T2+R0lNnZ/GE2hv+swd2L7uD0rvr24PYm6fNOkWq+lv0LjTv16owWo+rHjHap7d/4fkcGNnsImErcDhy7NC+6edVMOt1uCBw9ET86GtVtNmT/5J8OZa362h0XDjckuV70uV71lhsvrjnnyizgyX9XPJL7a+p9X7P/337HQKhknB4ug/Sv3a/2HKSVhvqraOy6EtVlD6tPcqHN4ebEZeJnkDPStbuE06+ZEVAKs+sP4RGTmrZ691GoSZBISZ7GCapg7XNGv7JzV6/1CNth+ybk80dN2cU5Tn09jifI0dHEy6LcrzyciS/zq6xTSt/7C2P2+dqD51uLthnSjcXuuP3KdxeaWCIdaMzgWl0WWotQw4z2pK6snxjESsJr7aw8l/eGOLv8A6mbS1SAc3WSOjPnrDOqkk8hdYnycWXGL9c84kUGidsIZOs2oiBo61atZOHYguCZ3Maz6x+pF4AlLplGh4mW6d7PIHJb+uaVqB6X+etX4WzTXt+4ZMtvpaGYYko32EXWzdjFiBNjGYJgoOsQJtpM0KePGltX29tbmL2sEu+AusGrTpd1s/27PVcEL68LdWP6l9GzoHmxEzE74n0e9McEjySTESsQL0seg0DVXR2+O728Omyxvti9axb9pAq7Py4XetwNdVOM0tan/fYIlVcxhMWHL6W7Ufn5RHa+nelUJ1n/7ZC4ZKJRdZS9EY62cebkn+OYRbre9tW7PUeDJaE1QVrc091nWY8BdagXLQeGvE5aDzrfvBIe3/8Bzf0357fI9VQ9wTBUOjoW2K9XtQMEzav0Ha/d/WbeLx9OZK582xams6BqZ4aOpnhbKjH0R/lh9Y68d3JTe3z5ovzX24Z2U+DcJMAsJM9jJNU0dqmuPBZsfhWu2pqus0YipRMODRyKI8DS/K1ciiXI0YkKcRRbkaUZSnwUG/XK4sDjrhNmn/eum9/7T+0MdO8KHG9uagjrx5CTVAiTVBw60/cnmD7GkqsUvtESvU7H3dCkOnC2SG2wo53lzr5DVsWnt4GTC6+58pErZOQrlFZ9dpubVZ2v2qtO1Zae/vz66moHC4NGSS1Rl9yMVWZ9xgcfeeG2qINn/GmkCjS+MJa1vxhdLU260TkR0aT1rBZsdL0r71Z/6csYDh8lqhJdaHqiOXp3uhNMZfaB2r2Mm5dIr1PmcTsiNhq0yfbJYORZsgTdMKLcUT2wNM7oDuv+bp3qfxhBVw6o5atYoDx1vf0bP9p6DxpBWAG09YzbiJgwyaa9q3efzWsSmdYt0GS07/mqFGq/Zt92tWuKk73IsPK+vvS2zG9/HXWDXGNiLMJCDM9D2NoTZ9VNWg3UfrtKeqXnuitxXVjTrTt9nvcalsQK6G9stRab8cDe0X0ND+OSottO6XFAbkPd3Q8UwXbktofmmw/nOM/YearTVVkXB0tFS4PbjEmtTc3sz5XHVHpQNvWT8DmdGRctFbM6J4E1LhMCu89PaE6ZTGk9ZJ8PjuhP5V0aWrGiOX1+oDMvgCafD50ZnAL2ivgYqHsWgwi9VsNBxPqF2bcnbhFN1nmlb/oI9+b/U3igemDqEpVG/98zBwrPUzLJ5gXbameIIVzFP4syHMJCDMnDuaQmEdPNmoAycadOBEow6cjN6eaNShU01Jw8S74jKkwcGAigsDGhz0q7jAb92P3g6O3g7I88mdzTU8gJ1M06pBqz1s9YdpbbKaUwacZ19ndTgnHB2F6sDPkjCTgDADSWoNR3SoukmfVDfp8KkmHYouh+NLs0Lh7nXScxnSgDyfivL8Ksr3qSjfr6I8nwZG1wfk+dQvx6v+eT71y/WqX46v+/PpAAAknd35m6v64Zzgdbs0cmCeRg7M63J/JGLqeEOLDp9qVlVts6rqWlRV26yjtS2qqovdtuhEQ4sipnS8PqTj9SHpaPfeP9/vsYJNrlf9c30qyPGqMLoUBBLWczwqzPEqGPAq3+9RMOCR3+PqW52aAcBmhBlAkstlWE1JwTMPU2wNR1TdGNKJ+ujS0KLj9SGdqG+J3z/RENKpxladagzpVFOrTFOqb2lTfUubPqnuxmiUDjwuQ/kBTzTceBX0e5TndyvP71Gez6M8v0f5frdy/e3reT6Pcn0e5fhcyvF6lOtzK9fnVo7PrVyfh2YyAH0KYQY4C163q1uhJyYSMVXb3KrqxlZVN4Z0qjGk6oZW1Ta3qqapfaltalNtwv1Y+JGktogZDUetks4+DHXF53FZ4cYbXXxd3/o9Lvm9bgWit/7E2+ji87jkc7vldRvWemy72y2vx5DP7Ypv97mpZQJgP8IMkEIul6F+uT71y/VplLpu4jqdSMRUQ8gKNfXNbaqL3tYn3DaG2lTfElZDS5saQm3WbUtY9S1tam4NqzFkLU2hNjW2huOjvUJtEYXaIjql1jMXIgV8bldS8PG6XdFtLnk9hnUbfYzX7ZLH5ZLHZcgTve92GfK6DbldRsI+6/Eelyv6OGvd67b2uQ3r8W6XIZfLkMdlyGVYt+6ExWVY7+MyYq/fvu52SYZhyG1Y21wuxfcZhtq3J+xzGdF9rtg+EeaAFMiKMPPEE0/on/7pn3TkyBFdeOGFWr58uT73uc85XSwgpVwuw2pWCnglG6YNMU1TLW0RNYXCamwNqykUXVqjS6hNTa2x8BNWc2tYLW0RtbRFrPXWiFrawu33o4EoFI7Ew1F8PWFbW4dRZKFwRKGw1BCy4VpZWchlRIOOy4iHrOTAY7Q/Jhp+OoajxMcYHR6vLp5vSEkhS+rw+gmPM+KvKxmK3sZfo31d0f2u2ByBiY812j+n9ZqJYS450CVFu9iVRhJeN/E1jA6fK/Y5Yu/XsbxWudqfa5U7cV/yc5X0fl18rg7Pi91X0v3Oz1dX+xKec0YJx0QJn0kdPlfizzH5WHR47hleL3a/05snfi86lD+2Lxjt++eUjA8zzz33nObPn68nnnhCs2bN0r/8y7/o6quv1gcffKDhw4c7XTwgaxiGoYDXrYDXrf5pfN9IxFQoHEkKP60dgk9b2FRrOHm9Ndwehtoiptqi+2LrrRFT4Ujs8abaIhG1hhO2xR4XNhUxTYUjHRbTeq1Ih20dH9cWsZ4few3TlMIJ2yLR+90+HqYUMU1rBegj7pkzWgv+/HzH3j/jh2ZPnz5dU6ZM0cqVK+PbLrjgAt14441asmRJp8e3tLSopaV9NtTa2lqVlZUxNBtASpnRYBMPOZHO6+GE+2HTClKxkBRJfH708Wbi60X3J25rX7dCo6nE97XKZKrzY2JZykx4jdjjTNOa5i+2L/a5krYp8XHRcJZwDGKPicSfn/yeUvvVqOL3oxtirxl/jw5lSyx30mfRacobfdH2/e2f14zujH2Wjp9fids6fe4O6/Fyt3+Yzp8l+bU/7ewbLX3n5yUcwMTP0l7W5G2JZWk/ygnl7fCzSPz5xB+X+BmTPq/1nl+fPVoPzD3DNcB6oM8MzQ6FQtqyZYu+973vJW2fN2+eNm7c2OVzlixZoocftvf6EADwaaz+NJL70xsOANgso2fyOn78uMLhsIqLk69bUlxcrMrKyi6f8+CDD6qmpia+VFRUpKOoAADAIRldMxPTsfe/aZqnHRHg9/vl9/vTUSwAAJABMrpmZuDAgXK73Z1qYaqqqjrV1gAAgHNTRocZn8+nqVOnau3atUnb165dq5kzZzpUKgAAkEkyvpnpgQce0Fe+8hVNmzZNM2bM0FNPPaWDBw/qrrvucrpoAAAgA2R8mLnlllt04sQJ/ehHP9KRI0c0ceJE/e53v9OIESOcLhoAAMgAGT/PTG+dzTh1AACQGc7m/J3RfWYAAAA+DWEGAABkNcIMAADIaoQZAACQ1QgzAAAgqxFmAABAViPMAACArJbxk+b1VmwandraWodLAgAAuit23u7OdHh9PszU1dVJksrKyhwuCQAAOFt1dXUqLCw842P6/AzAkUhEhw8fVjAYlGEYtr52bW2tysrKVFFRwezCvcSxtBfH0z4cS3txPO3T14+laZqqq6tTaWmpXK4z94rp8zUzLpdLw4YNS+l7FBQU9MkvkhM4lvbieNqHY2kvjqd9+vKx/LQamRg6AAMAgKxGmAEAAFmNMNMLfr9fP/zhD+X3+50uStbjWNqL42kfjqW9OJ724Vi26/MdgAEAQN9GzQwAAMhqhBkAAJDVCDMAACCrEWYAAEBWI8z00BNPPKFRo0YpEAho6tSp+sMf/uB0kbLCm2++qeuvv16lpaUyDEMvvfRS0n7TNLVo0SKVlpYqJydHc+bM0Y4dO5wpbIZbsmSJLr30UgWDQQ0ePFg33nijdu3alfQYjmf3rFy5UpMmTYpPPjZjxgy9+uqr8f0cx55bsmSJDMPQ/Pnz49s4nt23aNEiGYaRtJSUlMT3cywthJkeeO655zR//nwtXLhQW7du1ec+9zldffXVOnjwoNNFy3gNDQ2aPHmyVqxY0eX+pUuXatmyZVqxYoXKy8tVUlKiuXPnxq+xhXYbNmzQvffeq02bNmnt2rVqa2vTvHnz1NDQEH8Mx7N7hg0bpkcffVSbN2/W5s2bdcUVV+iGG26InxQ4jj1TXl6up556SpMmTUrazvE8OxdeeKGOHDkSX7Zv3x7fx7GMMnHWPvOZz5h33XVX0rbzzz/f/N73vudQibKTJPPFF1+M349EImZJSYn56KOPxrc1NzebhYWF5pNPPulACbNLVVWVKcncsGGDaZocz97q37+/+fOf/5zj2EN1dXXm2LFjzbVr15qzZ88277//ftM0+V6erR/+8Ifm5MmTu9zHsWxHzcxZCoVC2rJli+bNm5e0fd68edq4caNDpeob9u/fr8rKyqRj6/f7NXv2bI5tN9TU1EiSBgwYIInj2VPhcFirVq1SQ0ODZsyYwXHsoXvvvVfXXnutrrrqqqTtHM+zt2fPHpWWlmrUqFH60pe+pH379kniWCbq8xeatNvx48cVDodVXFyctL24uFiVlZUOlapviB2/ro7tgQMHnChS1jBNUw888IAuu+wyTZw4URLH82xt375dM2bMUHNzs/Lz8/Xiiy9qwoQJ8ZMCx7H7Vq1apXfffVfl5eWd9vG9PDvTp0/Xr371K40bN05Hjx7VP/zDP2jmzJnasWMHxzIBYaaHDMNIum+aZqdt6BmO7dm777779N577+mtt97qtI/j2T3jx4/Xtm3bdOrUKa1evVq33367NmzYEN/PceyeiooK3X///VqzZo0CgcBpH8fx7J6rr746vn7RRRdpxowZGj16tJ555hl99rOflcSxlOgAfNYGDhwot9vdqRamqqqqUzrG2Yn10OfYnp1vfOMb+s1vfqN169Zp2LBh8e0cz7Pj8/k0ZswYTZs2TUuWLNHkyZP1s5/9jON4lrZs2aKqqipNnTpVHo9HHo9HGzZs0GOPPSaPxxM/ZhzPnsnLy9NFF12kPXv28N1MQJg5Sz6fT1OnTtXatWuTtq9du1YzZ850qFR9w6hRo1RSUpJ0bEOhkDZs2MCx7YJpmrrvvvv0wgsv6I033tCoUaOS9nM8e8c0TbW0tHAcz9KVV16p7du3a9u2bfFl2rRpuu2227Rt2zadd955HM9eaGlp0c6dOzVkyBC+m4kc63qcxVatWmV6vV7zF7/4hfnBBx+Y8+fPN/Py8syPP/7Y6aJlvLq6OnPr1q3m1q1bTUnmsmXLzK1bt5oHDhwwTdM0H330UbOwsNB84YUXzO3bt5tf/vKXzSFDhpi1tbUOlzzz3H333WZhYaG5fv1688iRI/GlsbEx/hiOZ/c8+OCD5ptvvmnu37/ffO+998yHHnrIdLlc5po1a0zT5Dj2VuJoJtPkeJ6Nb3/72+b69evNffv2mZs2bTKvu+46MxgMxs83HEsLYaaHHn/8cXPEiBGmz+czp0yZEh8OizNbt26dKanTcvvtt5umaQ01/OEPf2iWlJSYfr/f/PznP29u377d2UJnqK6OoyTz6aefjj+G49k9d955Z/z3edCgQeaVV14ZDzKmyXHsrY5hhuPZfbfccos5ZMgQ0+v1mqWlpeZNN91k7tixI76fY2kxTNM0nakTAgAA6D36zAAAgKxGmAEAAFmNMAMAALIaYQYAAGQ1wgwAAMhqhBkAAJDVCDMAACCrEWYAAEBWI8wAOOesX79ehmHo1KlTThcFgA0IMwAAIKsRZgAAQFYjzABIO9M0tXTpUp133nnKycnR5MmT9etf/1pSexPQK6+8osmTJysQCGj69Onavn170musXr1aF154ofx+v0aOHKmf/OQnSftbWlq0YMEClZWVye/3a+zYsfrFL36R9JgtW7Zo2rRpys3N1cyZM7Vr167UfnAAKUGYAZB2f//3f6+nn35aK1eu1I4dO/Stb31Lf/VXf6UNGzbEH/Od73xHP/7xj1VeXq7BgwfrC1/4glpbWyVZIeTmm2/Wl770JW3fvl2LFi3S97//ff3yl7+MP/+v//qvtWrVKj322GPauXOnnnzySeXn5yeVY+HChfrJT36izZs3y+Px6M4770zL5wdgL66aDSCtGhoaNHDgQL3xxhuaMWNGfPtXv/pVNTY26mtf+5ouv/xyrVq1Srfccosk6eTJkxo2bJh++ctf6uabb9Ztt92mY8eOac2aNfHnL1iwQK+88op27Nih3bt3a/z48Vq7dq2uuuqqTmVYv369Lr/8cr3++uu68sorJUm/+93vdO2116qpqUmBQCDFRwGAnaiZAZBWH3zwgZqbmzV37lzl5+fHl1/96lf66KOP4o9LDDoDBgzQ+PHjtXPnTknSzp07NWvWrKTXnTVrlvbs2aNwOKxt27bJ7XZr9uzZZyzLpEmT4utDhgyRJFVVVfX6MwJIL4/TBQBwbolEIpKkV155RUOHDk3a5/f7kwJNR4ZhSLL63MTWYxIrmXNycrpVFq/X2+m1Y+UDkD2omQGQVhMmTJDf79fBgwc1ZsyYpKWsrCz+uE2bNsXXq6urtXv3bp1//vnx13jrrbeSXnfjxo0aN26c3G63LrroIkUikaQ+OAD6LmpmAKRVMBjU3/3d3+lb3/qWIpGILrvsMtXW1mrjxo3Kz8/XiBEjJEk/+tGPVFRUpOLiYi1cuFADBw7UjTfeKEn69re/rUsvvVSPPPKIbrnlFr399ttasWKFnnjiCUnSyJEjdfvtt+vOO+/UY489psmTJ+vAgQOqqqrSzTff7NRHB5AihBkAaffII49o8ODBWrJkifbt26d+/fppypQpeuihh+LNPI8++qjuv/9+7dmzR5MnT9ZvfvMb+Xw+SdKUKVP0/PPP6wc/+IEeeeQRDRkyRD/60Y90xx13xN9j5cqVeuihh3TPPffoxIkTGj58uB566CEnPi6AFGM0E4CMEhtpVF1drX79+jldHABZgD4zAAAgqxFmAABAVqOZCQAAZDVqZgAAQFYjzAAAgKxGmAEAAFmNMAMAALIaYQYAAGQ1wgwAAMhqhBkAAJDVCDMAACCr/X/ENjZCOCOBeQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
