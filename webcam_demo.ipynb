{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import numpy as np\n",
    "def draw_korean_text(frame, text, position, font_path, font_size, color):\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    img_pil = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "    return np.array(img_pil)\n",
    "\n",
    "font_path = \"models/korean_font/NanumGothic.ttf\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "emotions_korean = [\"분노\", \"슬픔\",  \"당황\", \"기쁨\", \"중립\"]\n",
    "emotions = [\"angry\", \"sad\", \"embarrassed\", \"happy\", \"neutral\"]\n",
    "\n",
    "\n",
    "model_path = \"v2_final.hdf5\"\n",
    "# model_path = \"effb0_final.hdf5\"\n",
    "model = load_model(model_path)\n",
    "input_size = (48,48)\n",
    "is_grey = True\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(rgb_frame)\n",
    "\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, ic = frame.shape\n",
    "            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "\n",
    "            # 얼굴 부분 자르기\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            try:\n",
    "                face = cv2.resize(face, input_size) \n",
    "                if is_grey: #흑백\n",
    "                    face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY) \n",
    "                face = face / 255.0 # 정규화\n",
    "                face = np.expand_dims(face, axis=0)\n",
    "                face = np.expand_dims(face, axis=-1)\n",
    "\n",
    "                # 감정 예측\n",
    "                prediction = model.predict(face,verbose = 0)\n",
    "                emotion = emotions_korean[np.argmax(prediction)]\n",
    "\n",
    "                # 텍스트로 감정 표시\n",
    "                # cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "                frame = draw_korean_text(frame, emotion, (x, y - 30), font_path, 20, (36,255,12))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            # 얼굴에 BBOX 그리기\n",
    "            # mp_drawing.draw_detection(frame, detection)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "    # 결과 보여주기\n",
    "    cv2.imshow('Emotion Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
